{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "output_prefix = '/vol/bmd/yanyul/UKB/ptrs-tf/models/elastic_net_alpha_{alpha}_British'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../code/\")\n",
    "import util_ElasticNet, lib_LinearAlgebra, util_hdf5, lib_ElasticNet, lib_Checker, util_Stats\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py, yaml, functools\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import reload\n",
    "lib_LinearAlgebra = reload(lib_LinearAlgebra)\n",
    "util_ElasticNet = reload(util_ElasticNet)\n",
    "util_hdf5 = reload(util_hdf5)\n",
    "lib_ElasticNet = reload(lib_ElasticNet)\n",
    "lib_Checker = reload(lib_Checker)\n",
    "util_Stats = reload(util_Stats)\n",
    "import util_hdf5\n",
    "import logging, sys\n",
    "import seaborn as sns\n",
    "logging.basicConfig(\n",
    "    level = logging.INFO, \n",
    "    stream = sys.stderr,\n",
    "#     filename = logfile,\n",
    "    format = '%(asctime)s  %(message)s',\n",
    "    datefmt = '%Y-%m-%d %I:%M:%S %p'\n",
    ")\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_visible_devices(gpus[1], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size in British set is 4096\n"
     ]
    }
   ],
   "source": [
    "population = 'British'\n",
    "\n",
    "# set path to British data\n",
    "hdf5_british = f'/vol/bmd/yanyul/UKB/predicted_expression_tf2/ukb_imp_x_ctimp_Whole_Blood_{population}.hdf5'\n",
    "\n",
    "# data scheme specifying which are traits and covariates\n",
    "scheme_yaml = '../misc_files/data_scheme.yaml'\n",
    "\n",
    "# loading names of traits/covariates\n",
    "# the order is matched with the data being loaded\n",
    "feature_dic = util_hdf5.read_yaml(scheme_yaml)\n",
    "with h5py.File(hdf5_british, 'r') as f:\n",
    "    features = f['columns_y'][:].astype('str')\n",
    "    sample_size = f['y'].shape[0]\n",
    "    y = f['y'][:]\n",
    "    genes = f['columns_x'][:].astype('str')\n",
    "covar_indice = np.where(np.isin(features, feature_dic['covar_names']))[0]\n",
    "trait_indice = np.where(np.isin(features, feature_dic['outcome_names']))[0]\n",
    "\n",
    "# load data_scheme for training\n",
    "batch_size = 2 ** 12\n",
    "print(f'batch_size in British set is {batch_size}')\n",
    "data_scheme, sample_size = util_hdf5.build_data_scheme(\n",
    "    hdf5_british, \n",
    "    scheme_yaml, \n",
    "    batch_size = batch_size, \n",
    "    inv_norm_y = True\n",
    ")\n",
    "\n",
    "# set validation and test set as the first and second batch\n",
    "dataset_valid = data_scheme.dataset.take(1)\n",
    "data_scheme.dataset = data_scheme.dataset.skip(1)\n",
    "dataset_test = data_scheme.dataset.take(1)\n",
    "data_scheme.dataset = data_scheme.dataset.skip(1)\n",
    "dataset_insample = data_scheme.dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_list = genes[data_scheme.get_indice_x()]\n",
    "trait_list = features[data_scheme.outcome_indice]\n",
    "covar_list = features[data_scheme.covariate_indice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_list = [0.1, 0.5, 0.9]\n",
    "model_list = {}\n",
    "for alpha in alpha_list:\n",
    "    filename = f'/vol/bmd/yanyul/UKB/ptrs-tf/models/elastic_net_alpha_{alpha}_British.hdf5'\n",
    "    model_list[alpha] = lib_LinearAlgebra.ElasticNetEstimator('', None, minimal_load = True)\n",
    "    model_list[alpha].minimal_load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  /vol/bmd/yanyul/UKB/ptrs-tf/models/elastic_net_alpha_0.1_British.export_model/  already exists\n",
      " Working on height\n",
      " Working on dbp\n",
      " Working on sbp\n",
      " Working on bmi\n",
      " Working on wbc\n",
      " Working on rbc\n",
      " Working on hb\n",
      " Working on ht\n",
      " Working on mcv\n",
      " Working on mch\n",
      " Working on mchc\n",
      " Working on platelet\n",
      " Working on lymphocyte\n",
      " Working on monocyte\n",
      " Working on neutrophil\n",
      " Working on eosinophil\n",
      " Working on basophil\n",
      "Directory  /vol/bmd/yanyul/UKB/ptrs-tf/models/elastic_net_alpha_0.5_British.export_model/  already exists\n",
      " Working on height\n",
      " Working on dbp\n",
      " Working on sbp\n",
      " Working on bmi\n",
      " Working on wbc\n",
      " Working on rbc\n",
      " Working on hb\n",
      " Working on ht\n",
      " Working on mcv\n",
      " Working on mch\n",
      " Working on mchc\n",
      " Working on platelet\n",
      " Working on lymphocyte\n",
      " Working on monocyte\n",
      " Working on neutrophil\n",
      " Working on eosinophil\n",
      " Working on basophil\n",
      "Directory  /vol/bmd/yanyul/UKB/ptrs-tf/models/elastic_net_alpha_0.9_British.export_model/  already exists\n",
      " Working on height\n",
      " Working on dbp\n",
      " Working on sbp\n",
      " Working on bmi\n",
      " Working on wbc\n",
      " Working on rbc\n",
      " Working on hb\n",
      " Working on ht\n",
      " Working on mcv\n",
      " Working on mch\n",
      " Working on mchc\n",
      " Working on platelet\n",
      " Working on lymphocyte\n",
      " Working on monocyte\n",
      " Working on neutrophil\n",
      " Working on eosinophil\n",
      " Working on basophil\n"
     ]
    }
   ],
   "source": [
    "def save_list(mylist, output):\n",
    "    with open(output, 'w') as f:\n",
    "        for l in mylist:\n",
    "            f.write(l + '\\n')\n",
    "\n",
    "def gen_dir(dirname):\n",
    "    if not os.path.exists(dirname):\n",
    "        os.mkdir(dirname)\n",
    "        print(\"Directory \" , dirname ,  \" Created \")\n",
    "    else:    \n",
    "        print(\"Directory \" , dirname ,  \" already exists\")\n",
    "\n",
    "# save gene list, trait list, and covariate list\n",
    "for alpha in alpha_list:\n",
    "    gene_out = output_prefix.format(alpha=alpha) + '.gene_list.txt'\n",
    "    save_list(gene_list, gene_out)\n",
    "    trait_out = output_prefix.format(alpha=alpha) + '.trait_list.txt'\n",
    "    save_list(trait_list, trait_out)\n",
    "    covar_out = output_prefix.format(alpha=alpha) + '.covar_list.txt'\n",
    "    save_list(covar_list, covar_out)\n",
    "    outdir = output_prefix.format(alpha=alpha) + '.export_model/'\n",
    "    gen_dir(outdir)\n",
    "    betas = model_list[alpha].beta_hat_path[:]\n",
    "    gene_df = pd.DataFrame({'gene_id': gene_list})\n",
    "    for tidx, trait in enumerate(trait_list):\n",
    "        print(f' Working on {trait}')\n",
    "        outputfile = outdir + f'weights.{trait}.tsv.gz'\n",
    "        weight_mat = betas[:, tidx, :].numpy()\n",
    "        weight_mat = weight_mat[:, np.abs(weight_mat).sum(axis=0) != 0]\n",
    "        weight_df = pd.concat((gene_df, pd.DataFrame(weight_mat, columns=[ f'model_{idx}' for idx in range(weight_mat.shape[1]) ])), axis=1)\n",
    "        weight_df.to_csv(outputfile, index=False, compression='gzip', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_list[alpha].beta_hat_path.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
