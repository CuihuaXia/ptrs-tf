{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../code')\n",
    "from importlib import reload  \n",
    "import lib_LinearAlgebra\n",
    "import lib_cnnPTRS, util_misc\n",
    "lib_LinearAlgebra = reload(lib_LinearAlgebra)\n",
    "lib_cnnPTRS = reload(lib_cnnPTRS)\n",
    "util_misc = reload(util_misc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inter_term(x, beta, i, j):\n",
    "    return x[:, i, np.newaxis] * x[:, j, np.newaxis] @ beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "k = 30\n",
    "n_outcome = 4\n",
    "kcovar = 20\n",
    "beta = np.reshape(np.array(range(1, k * n_outcome + 1)), newshape = [k, n_outcome])\n",
    "bcovar = np.reshape(np.array(range(1, kcovar * n_outcome + 1)), newshape = [kcovar, n_outcome]) * 0.2\n",
    "intercepts = np.array([230, 250, 270, 290])\n",
    "\n",
    "x = np.random.normal(size = [n, k])\n",
    "covar = np.random.normal(size = [n, kcovar])\n",
    "y = np.matmul(x, beta) + np.matmul(covar, bcovar) + np.random.normal(size = [n, n_outcome]) + intercepts + inter_term(x, beta[np.newaxis, 10, :] * 10, 0, 1) + inter_term(x, beta[np.newaxis, 5, :] * 10, 2, 3) + inter_term(x, beta[np.newaxis, 7, :] * 10, 0, 2) + inter_term(x, beta[np.newaxis, 5, :] * 10, 1, 3) + inter_term(x, beta[np.newaxis, 9, :] * 10, 0, 3) + inter_term(x, beta[np.newaxis, 12, :] * 10, 1, 2)\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x, np.concatenate((y, covar), axis = 1)))\n",
    "dataset = dataset.map(lambda x, y: (tf.cast(x, tf.float32), tf.cast(y, tf.float32)))\n",
    "dataset = dataset.batch(7)\n",
    "tempx = np.concatenate((x, covar), axis = 1)\n",
    "tempx = tempx[:, :, np.newaxis]\n",
    "tempy = y[:, 0, np.newaxis]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs_and_y(dataset, n_outcome, block = 100000000):\n",
    "    for inputs, y in dataset.unbatch().batch(block):\n",
    "#         inputs = [inputs, y[:, n_outcome:]]\n",
    "#         y = y[:, :n_outcome]\n",
    "        break\n",
    "    return inputs, y\n",
    "\n",
    "# data splitting \n",
    "dataset_train = dataset.take(100)\n",
    "dataset_valid = dataset.skip(100).take(15)\n",
    "dataset_test = dataset.skip(115).take(100)\n",
    "\n",
    "ele_valid = get_inputs_and_y(dataset_valid, n_outcome)\n",
    "ele_test = get_inputs_and_y(dataset_test, n_outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([30])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ele_valid[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fe1c03c2dd0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_scheme = lib_LinearAlgebra.DataScheme(\n",
    "    dataset = dataset_train, \n",
    "    X_index = 0, \n",
    "    Y_index = 1, \n",
    "    outcome_indice = [ 0, 1, 2, 3 ], \n",
    "    covariate_indice = np.array([ i for i in range(n_outcome, kcovar + n_outcome) ])\n",
    ")\n",
    "\n",
    "solver = lib_LinearAlgebra.LeastSquaredEstimator(data_scheme, normalizer = False, intercept = True)\n",
    "\n",
    "solver.solve()\n",
    "\n",
    "o = solver.predict_x(dataset_test) \n",
    "ytest_ls = o['y']\n",
    "ytest_pred_ls = o['y_pred_from_x']\n",
    "plt.scatter(ytest_ls, ytest_pred_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try `cnnPTRS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 30, 1)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "layer1_conv (Conv1D)            (None, 27, 32)       160         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer1_maxpool (MaxPooling1D)   (None, 13, 32)       0           layer1_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer1_dropout (Dropout)        (None, 13, 32)       0           layer1_maxpool[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer2_conv (Conv1D)            (None, 10, 64)       8256        layer1_dropout[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer2_maxpool (MaxPooling1D)   (None, 2, 64)        0           layer2_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer2_dropout (Dropout)        (None, 2, 64)        0           layer2_maxpool[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 128)          0           layer2_dropout[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 20)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ptrs_dense (Dense)              (None, 4)            512         flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "covar_dense (Dense)             (None, 4)            84          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 4)            0           ptrs_dense[0][0]                 \n",
      "                                                                 covar_dense[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 9,012\n",
      "Trainable params: 9,012\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model = util_misc.load_ordered_yaml('../misc_files/cnn_test.yaml')\n",
    "\n",
    "cnn = lib_cnnPTRS.cnnPTRS(cnn_model, data_scheme, normalizer = True)\n",
    "\n",
    "cnn.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ele_valid[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10 : loss 1073478.88 ; validation-accuracy: 0.000104667619\n",
      "Step 20 : loss 568179 ; validation-accuracy: 0.00528853387\n",
      "Step 30 : loss 1749598.12 ; validation-accuracy: 0.0117232986\n",
      "Step 40 : loss 525214.375 ; validation-accuracy: 0.0218533128\n",
      "Step 50 : loss 5366067 ; validation-accuracy: 0.0368835628\n",
      "Step 60 : loss 423507.562 ; validation-accuracy: 0.0539066792\n",
      "Step 70 : loss 529563.375 ; validation-accuracy: 0.0660188049\n",
      "Step 80 : loss 761312.875 ; validation-accuracy: 0.0746908411\n",
      "Step 90 : loss 246884.109 ; validation-accuracy: 0.094914645\n",
      "Step 100 : loss 1240974.88 ; validation-accuracy: 0.124967664\n",
      "Step 110 : loss 1059421.12 ; validation-accuracy: 0.159108579\n",
      "Step 120 : loss 577295.625 ; validation-accuracy: 0.175422966\n",
      "Step 130 : loss 1.74343e+06 ; validation-accuracy: 0.186632484\n",
      "Step 140 : loss 532796.125 ; validation-accuracy: 0.195880562\n",
      "Step 150 : loss 5276712.5 ; validation-accuracy: 0.206380278\n",
      "Step 160 : loss 414089.062 ; validation-accuracy: 0.215430945\n",
      "Step 170 : loss 543850.875 ; validation-accuracy: 0.224051639\n",
      "Step 180 : loss 734144.688 ; validation-accuracy: 0.234250188\n",
      "Step 190 : loss 251684.156 ; validation-accuracy: 0.239337042\n",
      "Step 200 : loss 1162603.25 ; validation-accuracy: 0.239794284\n",
      "Step 210 : loss 1005391.5 ; validation-accuracy: 0.248949349\n",
      "Step 220 : loss 619116.062 ; validation-accuracy: 0.249664634\n",
      "Step 230 : loss 1700213.75 ; validation-accuracy: 0.251541436\n",
      "Step 240 : loss 559386.625 ; validation-accuracy: 0.25518465\n",
      "Step 250 : loss 5019091 ; validation-accuracy: 0.260798186\n",
      "Step 260 : loss 404407.438 ; validation-accuracy: 0.266933799\n",
      "Step 270 : loss 575049.375 ; validation-accuracy: 0.273366153\n",
      "Step 280 : loss 681207.625 ; validation-accuracy: 0.280588925\n",
      "Step 290 : loss 264062.562 ; validation-accuracy: 0.284237444\n",
      "Step 300 : loss 1029471.56 ; validation-accuracy: 0.285253257\n",
      "Step 310 : loss 919840.5 ; validation-accuracy: 0.289416969\n",
      "Step 320 : loss 646611.125 ; validation-accuracy: 0.290525109\n",
      "Step 330 : loss 1.62734e+06 ; validation-accuracy: 0.292139262\n",
      "Step 340 : loss 605678 ; validation-accuracy: 0.294467509\n",
      "Step 350 : loss 4688757 ; validation-accuracy: 0.297726125\n",
      "Step 360 : loss 406322.219 ; validation-accuracy: 0.30098176\n",
      "Step 370 : loss 608958 ; validation-accuracy: 0.304328293\n",
      "Step 380 : loss 626298.188 ; validation-accuracy: 0.308582813\n",
      "Step 390 : loss 280762.812 ; validation-accuracy: 0.311131656\n",
      "Step 400 : loss 983479.375 ; validation-accuracy: 0.311924309\n",
      "Step 410 : loss 878390.188 ; validation-accuracy: 0.313754827\n",
      "Step 420 : loss 665741.438 ; validation-accuracy: 0.313943148\n",
      "Step 430 : loss 1580047.38 ; validation-accuracy: 0.314608127\n",
      "Step 440 : loss 613423.438 ; validation-accuracy: 0.315430194\n",
      "Step 450 : loss 4637317 ; validation-accuracy: 0.316651\n",
      "Step 460 : loss 416712.594 ; validation-accuracy: 0.319125026\n",
      "Step 470 : loss 604952 ; validation-accuracy: 0.321407527\n",
      "Step 480 : loss 629883.438 ; validation-accuracy: 0.323975444\n",
      "Step 490 : loss 274494.906 ; validation-accuracy: 0.325247169\n",
      "Step 500 : loss 958790.812 ; validation-accuracy: 0.325219572\n",
      "Step 510 : loss 895878.312 ; validation-accuracy: 0.325757772\n",
      "Step 520 : loss 659397.062 ; validation-accuracy: 0.325435519\n",
      "Step 530 : loss 1557221 ; validation-accuracy: 0.325589836\n",
      "Step 540 : loss 621721.562 ; validation-accuracy: 0.325869411\n",
      "Step 550 : loss 4508448 ; validation-accuracy: 0.326515824\n",
      "Step 560 : loss 398451.938 ; validation-accuracy: 0.328225434\n",
      "Step 570 : loss 614862.812 ; validation-accuracy: 0.329885781\n",
      "Step 580 : loss 647566.625 ; validation-accuracy: 0.331609\n",
      "Step 590 : loss 276775.219 ; validation-accuracy: 0.332831621\n",
      "Step 600 : loss 945457.375 ; validation-accuracy: 0.332952797\n",
      "Step 610 : loss 853556.438 ; validation-accuracy: 0.33302319\n",
      "Step 620 : loss 630025.375 ; validation-accuracy: 0.332711875\n",
      "Step 630 : loss 1589240.25 ; validation-accuracy: 0.332584858\n",
      "Step 640 : loss 639366.562 ; validation-accuracy: 0.332573\n",
      "Step 650 : loss 4567656.5 ; validation-accuracy: 0.333154529\n",
      "Step 660 : loss 402741.031 ; validation-accuracy: 0.334228098\n",
      "Step 670 : loss 592530.938 ; validation-accuracy: 0.335197598\n",
      "Step 680 : loss 630873.875 ; validation-accuracy: 0.336357743\n",
      "Step 690 : loss 276598.625 ; validation-accuracy: 0.337032557\n",
      "Step 700 : loss 949826.875 ; validation-accuracy: 0.337010473\n",
      "Step 710 : loss 879320.812 ; validation-accuracy: 0.337302297\n",
      "Step 720 : loss 619005.062 ; validation-accuracy: 0.337283969\n",
      "Step 730 : loss 1516077.38 ; validation-accuracy: 0.337719679\n",
      "Step 740 : loss 630316.188 ; validation-accuracy: 0.337869525\n",
      "Step 750 : loss 4486205 ; validation-accuracy: 0.338479817\n",
      "Step 760 : loss 385845.938 ; validation-accuracy: 0.339838028\n",
      "Step 770 : loss 587897.375 ; validation-accuracy: 0.340794325\n",
      "Step 780 : loss 624481.688 ; validation-accuracy: 0.341429502\n",
      "Step 790 : loss 273390.906 ; validation-accuracy: 0.341985255\n",
      "Step 800 : loss 911149.125 ; validation-accuracy: 0.341929734\n",
      "Step 810 : loss 837483.688 ; validation-accuracy: 0.341488063\n",
      "Step 820 : loss 577941.688 ; validation-accuracy: 0.341047436\n",
      "Step 830 : loss 1474957.62 ; validation-accuracy: 0.340827644\n",
      "Step 840 : loss 619880.625 ; validation-accuracy: 0.340575576\n",
      "Step 850 : loss 4310868.5 ; validation-accuracy: 0.340968728\n",
      "Step 860 : loss 392907.219 ; validation-accuracy: 0.342279911\n",
      "Step 870 : loss 581601.312 ; validation-accuracy: 0.343185484\n",
      "Step 880 : loss 599567.312 ; validation-accuracy: 0.343858451\n",
      "Step 890 : loss 264637.688 ; validation-accuracy: 0.344647646\n",
      "Step 900 : loss 892316.812 ; validation-accuracy: 0.344655633\n",
      "Step 910 : loss 840601.688 ; validation-accuracy: 0.344119579\n",
      "Step 920 : loss 572106 ; validation-accuracy: 0.343767315\n",
      "Step 930 : loss 1446117.75 ; validation-accuracy: 0.343838364\n",
      "Step 940 : loss 612687.875 ; validation-accuracy: 0.343984604\n",
      "Step 950 : loss 4013858.5 ; validation-accuracy: 0.344713241\n",
      "Step 960 : loss 387697.219 ; validation-accuracy: 0.346143126\n",
      "Step 970 : loss 551363.625 ; validation-accuracy: 0.347080231\n",
      "Step 980 : loss 609073.562 ; validation-accuracy: 0.347336859\n",
      "Step 990 : loss 268386.188 ; validation-accuracy: 0.347947657\n",
      "Step 1000 : loss 919873.875 ; validation-accuracy: 0.347857237\n",
      "Step 1010 : loss 833864.875 ; validation-accuracy: 0.347270459\n",
      "Step 1020 : loss 533872.875 ; validation-accuracy: 0.346770674\n",
      "Step 1030 : loss 1474634.25 ; validation-accuracy: 0.347048789\n",
      "Step 1040 : loss 625421.125 ; validation-accuracy: 0.347307\n",
      "Step 1050 : loss 4188310.75 ; validation-accuracy: 0.34801048\n",
      "Step 1060 : loss 367632.062 ; validation-accuracy: 0.349201828\n",
      "Step 1070 : loss 535129.875 ; validation-accuracy: 0.34992072\n",
      "Step 1080 : loss 601845.125 ; validation-accuracy: 0.350323081\n",
      "Step 1090 : loss 267594.312 ; validation-accuracy: 0.350584894\n",
      "Step 1100 : loss 916271.688 ; validation-accuracy: 0.350162029\n",
      "Step 1110 : loss 814540.062 ; validation-accuracy: 0.34940815\n",
      "Step 1120 : loss 517075.156 ; validation-accuracy: 0.348925114\n",
      "Step 1130 : loss 1428194 ; validation-accuracy: 0.349211603\n",
      "Step 1140 : loss 602539.188 ; validation-accuracy: 0.34941417\n",
      "Step 1150 : loss 4125634 ; validation-accuracy: 0.349886417\n",
      "Step 1160 : loss 369986.156 ; validation-accuracy: 0.350753665\n",
      "Step 1170 : loss 548437.125 ; validation-accuracy: 0.351171553\n",
      "Step 1180 : loss 596384.625 ; validation-accuracy: 0.35148558\n",
      "Step 1190 : loss 241016.641 ; validation-accuracy: 0.35159573\n",
      "Step 1200 : loss 873293.562 ; validation-accuracy: 0.350965708\n",
      "Step 1210 : loss 784912.5 ; validation-accuracy: 0.350018442\n",
      "Step 1220 : loss 471787.938 ; validation-accuracy: 0.34958148\n",
      "Step 1230 : loss 1399417 ; validation-accuracy: 0.349931628\n",
      "Step 1240 : loss 607804.688 ; validation-accuracy: 0.350264966\n",
      "Step 1250 : loss 3712735.25 ; validation-accuracy: 0.350863278\n",
      "Step 1260 : loss 365837.844 ; validation-accuracy: 0.351815283\n",
      "Step 1270 : loss 507162.719 ; validation-accuracy: 0.352576405\n",
      "Step 1280 : loss 606570.125 ; validation-accuracy: 0.353490621\n",
      "Step 1290 : loss 268144.25 ; validation-accuracy: 0.353965521\n",
      "Step 1300 : loss 885722 ; validation-accuracy: 0.353350461\n",
      "Step 1310 : loss 789862 ; validation-accuracy: 0.352297276\n",
      "Step 1320 : loss 490271.594 ; validation-accuracy: 0.351435512\n",
      "Step 1330 : loss 1373446.12 ; validation-accuracy: 0.351349175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1340 : loss 611419.312 ; validation-accuracy: 0.351629019\n",
      "Step 1350 : loss 3828804.25 ; validation-accuracy: 0.352272034\n",
      "Step 1360 : loss 348385.438 ; validation-accuracy: 0.353493601\n",
      "Step 1370 : loss 530352.188 ; validation-accuracy: 0.354655296\n",
      "Step 1380 : loss 565214.062 ; validation-accuracy: 0.355917454\n",
      "Step 1390 : loss 270156.156 ; validation-accuracy: 0.35620454\n",
      "Step 1400 : loss 889709.875 ; validation-accuracy: 0.355276257\n",
      "Step 1410 : loss 739379.875 ; validation-accuracy: 0.353894919\n",
      "Step 1420 : loss 431525.719 ; validation-accuracy: 0.352937609\n",
      "Step 1430 : loss 1308285.12 ; validation-accuracy: 0.352692366\n",
      "Step 1440 : loss 611257.125 ; validation-accuracy: 0.352784932\n",
      "Step 1450 : loss 3901621.75 ; validation-accuracy: 0.353411943\n",
      "Step 1460 : loss 346059.312 ; validation-accuracy: 0.354543954\n",
      "Step 1470 : loss 519676.344 ; validation-accuracy: 0.355661422\n",
      "Step 1480 : loss 603381.062 ; validation-accuracy: 0.356808096\n",
      "Step 1490 : loss 243567.109 ; validation-accuracy: 0.356927454\n",
      "Step 1500 : loss 857851.812 ; validation-accuracy: 0.356003553\n",
      "Step 1510 : loss 805684.375 ; validation-accuracy: 0.35470742\n",
      "Step 1520 : loss 412976.438 ; validation-accuracy: 0.353798181\n",
      "Step 1530 : loss 1215044.25 ; validation-accuracy: 0.353800446\n",
      "Step 1540 : loss 564028.5 ; validation-accuracy: 0.354213685\n",
      "Step 1550 : loss 3712695.25 ; validation-accuracy: 0.355024308\n",
      "Step 1560 : loss 350277.156 ; validation-accuracy: 0.356106877\n",
      "Step 1570 : loss 523671.969 ; validation-accuracy: 0.357472241\n",
      "Step 1580 : loss 592899.562 ; validation-accuracy: 0.358644962\n",
      "Step 1590 : loss 247555.094 ; validation-accuracy: 0.358985454\n",
      "Step 1600 : loss 845211.875 ; validation-accuracy: 0.358289242\n",
      "Step 1610 : loss 729276.938 ; validation-accuracy: 0.357003272\n",
      "Step 1620 : loss 380314.5 ; validation-accuracy: 0.355931461\n",
      "Step 1630 : loss 1231239.25 ; validation-accuracy: 0.355957896\n",
      "Step 1640 : loss 574040.875 ; validation-accuracy: 0.356228679\n",
      "Step 1650 : loss 3631540.5 ; validation-accuracy: 0.356780052\n",
      "Step 1660 : loss 348055.406 ; validation-accuracy: 0.35772261\n",
      "Step 1670 : loss 475499.438 ; validation-accuracy: 0.358695209\n",
      "Step 1680 : loss 586841.688 ; validation-accuracy: 0.359661728\n",
      "Step 1690 : loss 236744.141 ; validation-accuracy: 0.359802932\n",
      "Step 1700 : loss 871366.375 ; validation-accuracy: 0.35912\n",
      "Step 1710 : loss 782165 ; validation-accuracy: 0.35781014\n",
      "Step 1720 : loss 374811.906 ; validation-accuracy: 0.356966794\n",
      "Step 1730 : loss 1272546.12 ; validation-accuracy: 0.356884837\n",
      "Step 1740 : loss 576963.625 ; validation-accuracy: 0.35722357\n",
      "Step 1750 : loss 3653220.5 ; validation-accuracy: 0.357914299\n",
      "Step 1760 : loss 340750.719 ; validation-accuracy: 0.35900715\n",
      "Step 1770 : loss 459109.844 ; validation-accuracy: 0.360185951\n",
      "Step 1780 : loss 556798.062 ; validation-accuracy: 0.361169875\n",
      "Step 1790 : loss 223178.297 ; validation-accuracy: 0.361344397\n",
      "Step 1800 : loss 867818.938 ; validation-accuracy: 0.360758454\n",
      "Step 1810 : loss 733944.5 ; validation-accuracy: 0.359686911\n",
      "Step 1820 : loss 361973.344 ; validation-accuracy: 0.359082311\n",
      "Step 1830 : loss 1210354.75 ; validation-accuracy: 0.359287083\n",
      "Step 1840 : loss 639271.125 ; validation-accuracy: 0.35950923\n",
      "Step 1850 : loss 3.67615e+06 ; validation-accuracy: 0.360159576\n",
      "Step 1860 : loss 350093.094 ; validation-accuracy: 0.361327767\n",
      "Step 1870 : loss 453761.281 ; validation-accuracy: 0.362432\n",
      "Step 1880 : loss 559260.375 ; validation-accuracy: 0.363408983\n",
      "Step 1890 : loss 248977 ; validation-accuracy: 0.363609791\n",
      "Step 1900 : loss 863367.562 ; validation-accuracy: 0.362877816\n",
      "Step 1910 : loss 701293.188 ; validation-accuracy: 0.361617237\n",
      "Step 1920 : loss 362405.156 ; validation-accuracy: 0.360827744\n",
      "Step 1930 : loss 1228183.62 ; validation-accuracy: 0.360826164\n",
      "Step 1940 : loss 619629.688 ; validation-accuracy: 0.361194313\n",
      "Step 1950 : loss 3248242.25 ; validation-accuracy: 0.361821532\n",
      "Step 1960 : loss 328277.531 ; validation-accuracy: 0.362448752\n",
      "Step 1970 : loss 503607.656 ; validation-accuracy: 0.363232583\n",
      "Step 1980 : loss 575173.75 ; validation-accuracy: 0.363956064\n",
      "Step 1990 : loss 255001.219 ; validation-accuracy: 0.364102\n",
      "Step 2000 : loss 854395.812 ; validation-accuracy: 0.363425493\n",
      "Step 2010 : loss 705226.938 ; validation-accuracy: 0.362359673\n",
      "Step 2020 : loss 372761.719 ; validation-accuracy: 0.361714959\n",
      "Step 2030 : loss 1225878.88 ; validation-accuracy: 0.362024873\n",
      "Step 2040 : loss 585984.938 ; validation-accuracy: 0.36266917\n",
      "Step 2050 : loss 3475456 ; validation-accuracy: 0.363251239\n",
      "Step 2060 : loss 342767 ; validation-accuracy: 0.363866866\n",
      "Step 2070 : loss 534114.125 ; validation-accuracy: 0.364400268\n",
      "Step 2080 : loss 551066.062 ; validation-accuracy: 0.364914536\n",
      "Step 2090 : loss 273467.688 ; validation-accuracy: 0.364816129\n",
      "Step 2100 : loss 835491.812 ; validation-accuracy: 0.364042282\n",
      "Step 2110 : loss 770186.312 ; validation-accuracy: 0.362882137\n",
      "Step 2120 : loss 347226.938 ; validation-accuracy: 0.362306148\n",
      "Step 2130 : loss 1178469.75 ; validation-accuracy: 0.362511933\n",
      "Step 2140 : loss 587566.375 ; validation-accuracy: 0.363062799\n",
      "Step 2150 : loss 3242545.25 ; validation-accuracy: 0.363783389\n",
      "Step 2160 : loss 352740.281 ; validation-accuracy: 0.364322603\n",
      "Step 2170 : loss 493321.906 ; validation-accuracy: 0.364685237\n",
      "Step 2180 : loss 603262.188 ; validation-accuracy: 0.365112334\n",
      "Step 2190 : loss 237005.891 ; validation-accuracy: 0.365157247\n",
      "Step 2200 : loss 857933 ; validation-accuracy: 0.364402711\n",
      "Step 2210 : loss 688657.438 ; validation-accuracy: 0.363498122\n",
      "Step 2220 : loss 334608.25 ; validation-accuracy: 0.362901449\n",
      "Step 2230 : loss 1201271.25 ; validation-accuracy: 0.363165915\n",
      "Step 2240 : loss 558363.938 ; validation-accuracy: 0.363809496\n",
      "Step 2250 : loss 3416383.25 ; validation-accuracy: 0.364614129\n",
      "Step 2260 : loss 353367.281 ; validation-accuracy: 0.365337342\n",
      "Step 2270 : loss 491724.75 ; validation-accuracy: 0.365715176\n",
      "Step 2280 : loss 593689.5 ; validation-accuracy: 0.366033852\n",
      "Step 2290 : loss 245168.969 ; validation-accuracy: 0.366024494\n",
      "Step 2300 : loss 874465.312 ; validation-accuracy: 0.365436524\n",
      "Step 2310 : loss 670691.375 ; validation-accuracy: 0.364508569\n",
      "Step 2320 : loss 312111.5 ; validation-accuracy: 0.363951862\n",
      "Step 2330 : loss 1112533.25 ; validation-accuracy: 0.3643426\n",
      "Step 2340 : loss 561574.562 ; validation-accuracy: 0.364941299\n",
      "Step 2350 : loss 3237928.25 ; validation-accuracy: 0.365629673\n",
      "Step 2360 : loss 342282.656 ; validation-accuracy: 0.366079569\n",
      "Step 2370 : loss 418111.062 ; validation-accuracy: 0.366453707\n",
      "Step 2380 : loss 607711.5 ; validation-accuracy: 0.366909117\n",
      "Step 2390 : loss 249991.578 ; validation-accuracy: 0.36692363\n",
      "Step 2400 : loss 827384.5 ; validation-accuracy: 0.366288364\n",
      "Step 2410 : loss 673792 ; validation-accuracy: 0.365427554\n",
      "Step 2420 : loss 334422.531 ; validation-accuracy: 0.365102082\n",
      "Step 2430 : loss 1171791.75 ; validation-accuracy: 0.365440428\n",
      "Step 2440 : loss 624138.562 ; validation-accuracy: 0.365984738\n",
      "Step 2450 : loss 3016840.75 ; validation-accuracy: 0.366612971\n",
      "Step 2460 : loss 357834.5 ; validation-accuracy: 0.36710152\n",
      "Step 2470 : loss 459058.562 ; validation-accuracy: 0.367432475\n",
      "Step 2480 : loss 576694.125 ; validation-accuracy: 0.367843539\n",
      "Step 2490 : loss 269631.531 ; validation-accuracy: 0.367981076\n",
      "Step 2500 : loss 816033.375 ; validation-accuracy: 0.367436141\n",
      "Step 2510 : loss 639232.125 ; validation-accuracy: 0.366509616\n",
      "Step 2520 : loss 341132.25 ; validation-accuracy: 0.366053641\n",
      "Step 2530 : loss 1231802.25 ; validation-accuracy: 0.366260439\n",
      "Step 2540 : loss 614709.375 ; validation-accuracy: 0.366709054\n",
      "Step 2550 : loss 3245150.25 ; validation-accuracy: 0.367413491\n",
      "Step 2560 : loss 335903.219 ; validation-accuracy: 0.368060529\n",
      "Step 2570 : loss 447111.344 ; validation-accuracy: 0.368430376\n",
      "Step 2580 : loss 583331.062 ; validation-accuracy: 0.36867696\n",
      "Step 2590 : loss 257112.672 ; validation-accuracy: 0.368770659\n",
      "Step 2600 : loss 836699.938 ; validation-accuracy: 0.368392855\n",
      "Step 2610 : loss 680943.375 ; validation-accuracy: 0.367622972\n",
      "Step 2620 : loss 330726.25 ; validation-accuracy: 0.367139399\n",
      "Step 2630 : loss 1056726.5 ; validation-accuracy: 0.367349923\n",
      "Step 2640 : loss 596026.625 ; validation-accuracy: 0.367759526\n",
      "Step 2650 : loss 3120099.25 ; validation-accuracy: 0.368343115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2660 : loss 344223.406 ; validation-accuracy: 0.368830025\n",
      "Step 2670 : loss 506573 ; validation-accuracy: 0.369145095\n",
      "Step 2680 : loss 581911.25 ; validation-accuracy: 0.369434118\n",
      "Step 2690 : loss 236274.891 ; validation-accuracy: 0.369335771\n",
      "Step 2700 : loss 817357.125 ; validation-accuracy: 0.36878413\n",
      "Step 2710 : loss 673917.562 ; validation-accuracy: 0.367936075\n",
      "Step 2720 : loss 355244.562 ; validation-accuracy: 0.367309868\n",
      "Step 2730 : loss 1139570.38 ; validation-accuracy: 0.367706329\n",
      "Step 2740 : loss 611202.812 ; validation-accuracy: 0.368401527\n",
      "Step 2750 : loss 3051491.25 ; validation-accuracy: 0.369123399\n",
      "Step 2760 : loss 364768.656 ; validation-accuracy: 0.369749904\n",
      "Step 2770 : loss 397653.562 ; validation-accuracy: 0.3701424\n",
      "Step 2780 : loss 644029.438 ; validation-accuracy: 0.370370805\n",
      "Step 2790 : loss 224303.484 ; validation-accuracy: 0.370408\n",
      "Step 2800 : loss 880207.188 ; validation-accuracy: 0.369861901\n",
      "Step 2810 : loss 674016.5 ; validation-accuracy: 0.368929625\n",
      "Step 2820 : loss 294989.781 ; validation-accuracy: 0.368540645\n",
      "Step 2830 : loss 1163680.25 ; validation-accuracy: 0.368938416\n",
      "Step 2840 : loss 589088.312 ; validation-accuracy: 0.36959815\n",
      "Step 2850 : loss 3546027.5 ; validation-accuracy: 0.370422065\n",
      "Step 2860 : loss 360529.594 ; validation-accuracy: 0.371058196\n",
      "Step 2870 : loss 432083.781 ; validation-accuracy: 0.371444821\n",
      "Step 2880 : loss 580962.188 ; validation-accuracy: 0.371835053\n",
      "Step 2890 : loss 210765.953 ; validation-accuracy: 0.37193653\n",
      "Step 2900 : loss 845659.188 ; validation-accuracy: 0.371484876\n",
      "Step 2910 : loss 693671.125 ; validation-accuracy: 0.370548\n",
      "Step 2920 : loss 317804.469 ; validation-accuracy: 0.370071769\n",
      "Step 2930 : loss 1174602.88 ; validation-accuracy: 0.370217234\n",
      "Step 2940 : loss 616682.188 ; validation-accuracy: 0.370809227\n",
      "Step 2950 : loss 2867685.5 ; validation-accuracy: 0.371588409\n",
      "Step 2960 : loss 341338.5 ; validation-accuracy: 0.37206769\n",
      "Step 2970 : loss 440743.062 ; validation-accuracy: 0.372430027\n",
      "Step 2980 : loss 583353.75 ; validation-accuracy: 0.372934878\n",
      "Step 2990 : loss 253005.172 ; validation-accuracy: 0.372972757\n",
      "Step 3000 : loss 829901.875 ; validation-accuracy: 0.372538835\n",
      "Step 3010 : loss 698992.312 ; validation-accuracy: 0.37170288\n",
      "Step 3020 : loss 360515.5 ; validation-accuracy: 0.371203721\n",
      "Step 3030 : loss 1173109.62 ; validation-accuracy: 0.371564895\n",
      "Step 3040 : loss 620593.375 ; validation-accuracy: 0.372228712\n",
      "Step 3050 : loss 3027045.5 ; validation-accuracy: 0.372847974\n",
      "Step 3060 : loss 335932.688 ; validation-accuracy: 0.373163104\n",
      "Step 3070 : loss 401486.719 ; validation-accuracy: 0.373301119\n",
      "Step 3080 : loss 508422.25 ; validation-accuracy: 0.373404801\n",
      "Step 3090 : loss 247022.141 ; validation-accuracy: 0.373385459\n",
      "Step 3100 : loss 798023.438 ; validation-accuracy: 0.373001516\n",
      "Step 3110 : loss 549432 ; validation-accuracy: 0.372286737\n",
      "Step 3120 : loss 292246.594 ; validation-accuracy: 0.3719576\n",
      "Step 3130 : loss 1110045.5 ; validation-accuracy: 0.372375637\n",
      "Step 3140 : loss 737707.125 ; validation-accuracy: 0.37308535\n",
      "Step 3150 : loss 3007254.5 ; validation-accuracy: 0.373784661\n",
      "Step 3160 : loss 378502.062 ; validation-accuracy: 0.374181151\n",
      "Step 3170 : loss 418162.312 ; validation-accuracy: 0.374253392\n",
      "Step 3180 : loss 614126.375 ; validation-accuracy: 0.37452358\n",
      "Step 3190 : loss 254687.25 ; validation-accuracy: 0.374622\n",
      "Step 3200 : loss 804670.312 ; validation-accuracy: 0.374268383\n",
      "Step 3210 : loss 724943.375 ; validation-accuracy: 0.37360543\n",
      "Step 3220 : loss 328823.469 ; validation-accuracy: 0.373427361\n",
      "Step 3230 : loss 1128975.75 ; validation-accuracy: 0.373905122\n",
      "Step 3240 : loss 535959.938 ; validation-accuracy: 0.374453336\n",
      "Step 3250 : loss 3140888.5 ; validation-accuracy: 0.375039279\n",
      "Step 3260 : loss 343782.531 ; validation-accuracy: 0.375338882\n",
      "Step 3270 : loss 474573.656 ; validation-accuracy: 0.375453413\n",
      "Step 3280 : loss 624725.312 ; validation-accuracy: 0.375799716\n",
      "Step 3290 : loss 229689.203 ; validation-accuracy: 0.376005799\n",
      "Step 3300 : loss 791094.062 ; validation-accuracy: 0.375789404\n",
      "Step 3310 : loss 726998.562 ; validation-accuracy: 0.375041395\n",
      "Step 3320 : loss 276412.594 ; validation-accuracy: 0.374697417\n",
      "Step 3330 : loss 1181238.12 ; validation-accuracy: 0.374906182\n",
      "Step 3340 : loss 526615.812 ; validation-accuracy: 0.375520498\n",
      "Step 3350 : loss 2866664.5 ; validation-accuracy: 0.376102537\n",
      "Step 3360 : loss 423584.5 ; validation-accuracy: 0.376368642\n",
      "Step 3370 : loss 419176.906 ; validation-accuracy: 0.376433\n",
      "Step 3380 : loss 659896.188 ; validation-accuracy: 0.376618862\n",
      "Step 3390 : loss 254428.109 ; validation-accuracy: 0.376703352\n",
      "Step 3400 : loss 832441.875 ; validation-accuracy: 0.376308024\n",
      "Step 3410 : loss 637709.438 ; validation-accuracy: 0.375513881\n",
      "Step 3420 : loss 296775.438 ; validation-accuracy: 0.375254542\n",
      "Step 3430 : loss 1125239.25 ; validation-accuracy: 0.375640094\n",
      "Step 3440 : loss 570230.875 ; validation-accuracy: 0.37650916\n",
      "Step 3450 : loss 2986458 ; validation-accuracy: 0.377222598\n",
      "Step 3460 : loss 382237.219 ; validation-accuracy: 0.377584934\n",
      "Step 3470 : loss 449842.562 ; validation-accuracy: 0.37791127\n",
      "Step 3480 : loss 531173.125 ; validation-accuracy: 0.378416449\n",
      "Step 3490 : loss 214614.922 ; validation-accuracy: 0.378514349\n",
      "Step 3500 : loss 796583.188 ; validation-accuracy: 0.378053248\n",
      "Step 3510 : loss 652751.625 ; validation-accuracy: 0.377186805\n",
      "Step 3520 : loss 284113 ; validation-accuracy: 0.376740158\n",
      "Step 3530 : loss 1223493.25 ; validation-accuracy: 0.376940638\n",
      "Step 3540 : loss 535170.438 ; validation-accuracy: 0.377563089\n",
      "Step 3550 : loss 3203220.75 ; validation-accuracy: 0.378222376\n",
      "Step 3560 : loss 320326.219 ; validation-accuracy: 0.378593296\n",
      "Step 3570 : loss 508016.219 ; validation-accuracy: 0.378827512\n",
      "Step 3580 : loss 590025.312 ; validation-accuracy: 0.379102826\n",
      "Step 3590 : loss 226525.781 ; validation-accuracy: 0.37911737\n",
      "Step 3600 : loss 804802.875 ; validation-accuracy: 0.37879324\n",
      "Step 3610 : loss 685088.312 ; validation-accuracy: 0.377991498\n",
      "Step 3620 : loss 282714.188 ; validation-accuracy: 0.377630621\n",
      "Step 3630 : loss 1166605.12 ; validation-accuracy: 0.378025472\n",
      "Step 3640 : loss 555529.188 ; validation-accuracy: 0.378713131\n",
      "Step 3650 : loss 2949094.5 ; validation-accuracy: 0.379335821\n",
      "Step 3660 : loss 328601.281 ; validation-accuracy: 0.379581034\n",
      "Step 3670 : loss 430160.156 ; validation-accuracy: 0.379722\n",
      "Step 3680 : loss 593778.062 ; validation-accuracy: 0.379921496\n",
      "Step 3690 : loss 270203.406 ; validation-accuracy: 0.379994184\n",
      "Step 3700 : loss 775634.688 ; validation-accuracy: 0.379580617\n",
      "Step 3710 : loss 674575.875 ; validation-accuracy: 0.378781\n",
      "Step 3720 : loss 307708.781 ; validation-accuracy: 0.378492862\n",
      "Step 3730 : loss 1208843.88 ; validation-accuracy: 0.378873467\n",
      "Step 3740 : loss 517655.344 ; validation-accuracy: 0.379625946\n",
      "Step 3750 : loss 2787820.75 ; validation-accuracy: 0.380431861\n",
      "Step 3760 : loss 417255.5 ; validation-accuracy: 0.380887538\n",
      "Step 3770 : loss 458731.25 ; validation-accuracy: 0.380953252\n",
      "Step 3780 : loss 609285.625 ; validation-accuracy: 0.381291628\n",
      "Step 3790 : loss 276253.156 ; validation-accuracy: 0.38138485\n",
      "Step 3800 : loss 775913.438 ; validation-accuracy: 0.380996764\n",
      "Step 3810 : loss 578620 ; validation-accuracy: 0.380191922\n",
      "Step 3820 : loss 328397.719 ; validation-accuracy: 0.379832\n",
      "Step 3830 : loss 1139819.62 ; validation-accuracy: 0.380080044\n",
      "Step 3840 : loss 586226.312 ; validation-accuracy: 0.38071\n",
      "Step 3850 : loss 2564590.5 ; validation-accuracy: 0.381341487\n",
      "Step 3860 : loss 355420.969 ; validation-accuracy: 0.381527\n",
      "Step 3870 : loss 488017.719 ; validation-accuracy: 0.381712\n",
      "Step 3880 : loss 544867.875 ; validation-accuracy: 0.381930649\n",
      "Step 3890 : loss 262308.438 ; validation-accuracy: 0.38205266\n",
      "Step 3900 : loss 787685.938 ; validation-accuracy: 0.381689876\n",
      "Step 3910 : loss 660668.812 ; validation-accuracy: 0.380661726\n",
      "Step 3920 : loss 307960.938 ; validation-accuracy: 0.380246133\n",
      "Step 3930 : loss 1135910.75 ; validation-accuracy: 0.380697608\n",
      "Step 3940 : loss 599487.438 ; validation-accuracy: 0.381558508\n",
      "Step 3950 : loss 2680991.75 ; validation-accuracy: 0.382442534\n",
      "Step 3960 : loss 324517.531 ; validation-accuracy: 0.382934093\n",
      "Step 3970 : loss 425648.344 ; validation-accuracy: 0.383068293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3980 : loss 595047.438 ; validation-accuracy: 0.383120269\n",
      "Step 3990 : loss 213695.141 ; validation-accuracy: 0.383094549\n",
      "Step 4000 : loss 867649.625 ; validation-accuracy: 0.382708758\n",
      "Step 4010 : loss 636980.875 ; validation-accuracy: 0.381546021\n",
      "Step 4020 : loss 341653.812 ; validation-accuracy: 0.381002694\n",
      "Step 4030 : loss 1117105.25 ; validation-accuracy: 0.381578565\n",
      "Step 4040 : loss 554708.812 ; validation-accuracy: 0.38233918\n",
      "Step 4050 : loss 2864760.75 ; validation-accuracy: 0.383125305\n",
      "Step 4060 : loss 352820.688 ; validation-accuracy: 0.383672386\n",
      "Step 4070 : loss 456729 ; validation-accuracy: 0.384013593\n",
      "Step 4080 : loss 570298.812 ; validation-accuracy: 0.384212822\n",
      "Step 4090 : loss 274793.312 ; validation-accuracy: 0.384275794\n",
      "Step 4100 : loss 819383.438 ; validation-accuracy: 0.383831859\n",
      "Step 4110 : loss 667276.188 ; validation-accuracy: 0.38280338\n",
      "Step 4120 : loss 332871.656 ; validation-accuracy: 0.38234362\n",
      "Step 4130 : loss 1087215.88 ; validation-accuracy: 0.382695675\n",
      "Step 4140 : loss 616872.562 ; validation-accuracy: 0.383388579\n",
      "Step 4150 : loss 2597929.75 ; validation-accuracy: 0.383972287\n",
      "Step 4160 : loss 383073.75 ; validation-accuracy: 0.384219676\n",
      "Step 4170 : loss 398387.438 ; validation-accuracy: 0.384205192\n",
      "Step 4180 : loss 670729.062 ; validation-accuracy: 0.384104\n",
      "Step 4190 : loss 216710.719 ; validation-accuracy: 0.384154499\n",
      "Step 4200 : loss 769291.625 ; validation-accuracy: 0.383797944\n",
      "Step 4210 : loss 692302.875 ; validation-accuracy: 0.382798761\n",
      "Step 4220 : loss 271353.719 ; validation-accuracy: 0.382415175\n",
      "Step 4230 : loss 1090230.75 ; validation-accuracy: 0.382830888\n",
      "Step 4240 : loss 564153.312 ; validation-accuracy: 0.383494586\n",
      "Step 4250 : loss 2657284.5 ; validation-accuracy: 0.384236962\n",
      "Step 4260 : loss 355828.812 ; validation-accuracy: 0.384614348\n",
      "Step 4270 : loss 442498.844 ; validation-accuracy: 0.384856552\n",
      "Step 4280 : loss 583366.062 ; validation-accuracy: 0.385108531\n",
      "Step 4290 : loss 301224.812 ; validation-accuracy: 0.385135353\n",
      "Step 4300 : loss 816554.812 ; validation-accuracy: 0.384783626\n",
      "Step 4310 : loss 553588.938 ; validation-accuracy: 0.383816212\n",
      "Step 4320 : loss 277938.844 ; validation-accuracy: 0.383487433\n",
      "Step 4330 : loss 1005716.5 ; validation-accuracy: 0.383910596\n",
      "Step 4340 : loss 519301.844 ; validation-accuracy: 0.384622961\n",
      "Step 4350 : loss 2519926 ; validation-accuracy: 0.385294199\n",
      "Step 4360 : loss 372488.906 ; validation-accuracy: 0.385713398\n",
      "Step 4370 : loss 445955.656 ; validation-accuracy: 0.385948509\n",
      "Step 4380 : loss 600637.625 ; validation-accuracy: 0.386118293\n",
      "Step 4390 : loss 273973.906 ; validation-accuracy: 0.386144\n",
      "Step 4400 : loss 802786.812 ; validation-accuracy: 0.385856867\n",
      "Step 4410 : loss 658304.375 ; validation-accuracy: 0.384848654\n",
      "Step 4420 : loss 292541.062 ; validation-accuracy: 0.384487838\n",
      "Step 4430 : loss 1160593.88 ; validation-accuracy: 0.384896129\n",
      "Step 4440 : loss 550566.062 ; validation-accuracy: 0.385377854\n",
      "Step 4450 : loss 2358755.75 ; validation-accuracy: 0.386041939\n",
      "Step 4460 : loss 386764.344 ; validation-accuracy: 0.386512488\n",
      "Step 4470 : loss 460338.656 ; validation-accuracy: 0.386817694\n",
      "Step 4480 : loss 553602.375 ; validation-accuracy: 0.387228787\n",
      "Step 4490 : loss 232454.094 ; validation-accuracy: 0.38748312\n",
      "Step 4500 : loss 864286.875 ; validation-accuracy: 0.387240559\n",
      "Step 4510 : loss 655275.938 ; validation-accuracy: 0.386349261\n",
      "Step 4520 : loss 287924.031 ; validation-accuracy: 0.385955095\n",
      "Step 4530 : loss 1121490.75 ; validation-accuracy: 0.386490256\n",
      "Step 4540 : loss 585884.438 ; validation-accuracy: 0.38734442\n",
      "Step 4550 : loss 2338027.5 ; validation-accuracy: 0.388167322\n",
      "Step 4560 : loss 439010.25 ; validation-accuracy: 0.388463855\n",
      "Step 4570 : loss 502674.094 ; validation-accuracy: 0.388580054\n",
      "Step 4580 : loss 619214.438 ; validation-accuracy: 0.388314217\n",
      "Step 4590 : loss 286130.188 ; validation-accuracy: 0.388305128\n",
      "Step 4600 : loss 867961.312 ; validation-accuracy: 0.387935221\n",
      "Step 4610 : loss 597461.375 ; validation-accuracy: 0.387191027\n",
      "Step 4620 : loss 312231.031 ; validation-accuracy: 0.386902511\n",
      "Step 4630 : loss 1089655 ; validation-accuracy: 0.387524545\n",
      "Step 4640 : loss 498017.406 ; validation-accuracy: 0.388464272\n",
      "Step 4650 : loss 2106142.75 ; validation-accuracy: 0.389337033\n",
      "Step 4660 : loss 369327.438 ; validation-accuracy: 0.389636576\n",
      "Step 4670 : loss 504450.562 ; validation-accuracy: 0.389822096\n",
      "Step 4680 : loss 649494 ; validation-accuracy: 0.389826298\n",
      "Step 4690 : loss 277468.812 ; validation-accuracy: 0.389937401\n",
      "Step 4700 : loss 785300.562 ; validation-accuracy: 0.390026927\n",
      "Step 4710 : loss 682881.188 ; validation-accuracy: 0.389384061\n",
      "Step 4720 : loss 288469.969 ; validation-accuracy: 0.389181197\n",
      "Step 4730 : loss 1055284.25 ; validation-accuracy: 0.389850914\n",
      "Step 4740 : loss 585233.938 ; validation-accuracy: 0.390530884\n",
      "Step 4750 : loss 2200986.75 ; validation-accuracy: 0.391472042\n",
      "Step 4760 : loss 416550.156 ; validation-accuracy: 0.392073274\n",
      "Step 4770 : loss 384764.938 ; validation-accuracy: 0.392252952\n",
      "Step 4780 : loss 560524.375 ; validation-accuracy: 0.392163634\n",
      "Step 4790 : loss 239611.922 ; validation-accuracy: 0.392184198\n",
      "Step 4800 : loss 817209.5 ; validation-accuracy: 0.39206171\n",
      "Step 4810 : loss 611552.125 ; validation-accuracy: 0.39126\n",
      "Step 4820 : loss 281764.562 ; validation-accuracy: 0.390931368\n",
      "Step 4830 : loss 1048485.69 ; validation-accuracy: 0.391834527\n",
      "Step 4840 : loss 576973.875 ; validation-accuracy: 0.39274925\n",
      "Step 4850 : loss 2793188.75 ; validation-accuracy: 0.393523276\n",
      "Step 4860 : loss 381198 ; validation-accuracy: 0.39434436\n",
      "Step 4870 : loss 441129.094 ; validation-accuracy: 0.394614697\n",
      "Step 4880 : loss 629875.562 ; validation-accuracy: 0.394595742\n",
      "Step 4890 : loss 228337.922 ; validation-accuracy: 0.394761741\n",
      "Step 4900 : loss 789795 ; validation-accuracy: 0.394346714\n",
      "Step 4910 : loss 596339.312 ; validation-accuracy: 0.393026888\n",
      "Step 4920 : loss 325132.406 ; validation-accuracy: 0.392389894\n",
      "Step 4930 : loss 960012.062 ; validation-accuracy: 0.39318943\n",
      "Step 4940 : loss 526887.75 ; validation-accuracy: 0.394171715\n",
      "Step 4950 : loss 2490921.25 ; validation-accuracy: 0.394993305\n",
      "Step 4960 : loss 396749.719 ; validation-accuracy: 0.395531595\n",
      "Step 4970 : loss 502012.812 ; validation-accuracy: 0.395781398\n",
      "Step 4980 : loss 619748.438 ; validation-accuracy: 0.395754248\n",
      "Step 4990 : loss 248908.531 ; validation-accuracy: 0.395934254\n",
      "Step 5000 : loss 791258.438 ; validation-accuracy: 0.395923823\n",
      "Step 5010 : loss 544875.125 ; validation-accuracy: 0.395331591\n",
      "Step 5020 : loss 255082.5 ; validation-accuracy: 0.395206153\n",
      "Step 5030 : loss 1071657.38 ; validation-accuracy: 0.395909905\n",
      "Step 5040 : loss 572133.188 ; validation-accuracy: 0.396839559\n",
      "Step 5050 : loss 2477867.5 ; validation-accuracy: 0.39771691\n",
      "Step 5060 : loss 481078.688 ; validation-accuracy: 0.39852488\n",
      "Step 5070 : loss 517057.156 ; validation-accuracy: 0.398616076\n",
      "Step 5080 : loss 647548.625 ; validation-accuracy: 0.39874965\n",
      "Step 5090 : loss 220105.641 ; validation-accuracy: 0.398886442\n",
      "Step 5100 : loss 832694.438 ; validation-accuracy: 0.398708403\n",
      "Step 5110 : loss 637616.125 ; validation-accuracy: 0.397675812\n",
      "Step 5120 : loss 282786.875 ; validation-accuracy: 0.397384048\n",
      "Step 5130 : loss 978980.562 ; validation-accuracy: 0.398061365\n",
      "Step 5140 : loss 601249.625 ; validation-accuracy: 0.39896813\n",
      "Step 5150 : loss 2521668.25 ; validation-accuracy: 0.39972502\n",
      "Step 5160 : loss 382353.969 ; validation-accuracy: 0.400358558\n",
      "Step 5170 : loss 435113.5 ; validation-accuracy: 0.400579035\n",
      "Step 5180 : loss 590979.625 ; validation-accuracy: 0.400339782\n",
      "Step 5190 : loss 249619.078 ; validation-accuracy: 0.40034\n",
      "Step 5200 : loss 707756.625 ; validation-accuracy: 0.400093168\n",
      "Step 5210 : loss 586688.75 ; validation-accuracy: 0.399090558\n",
      "Step 5220 : loss 319366.812 ; validation-accuracy: 0.39879\n",
      "Step 5230 : loss 1123036.38 ; validation-accuracy: 0.399398118\n",
      "Step 5240 : loss 585973.875 ; validation-accuracy: 0.399990976\n",
      "Step 5250 : loss 2191788.25 ; validation-accuracy: 0.400767893\n",
      "Step 5260 : loss 436093.969 ; validation-accuracy: 0.401010513\n",
      "Step 5270 : loss 437830.844 ; validation-accuracy: 0.4010849\n",
      "Step 5280 : loss 634659.312 ; validation-accuracy: 0.400941461\n",
      "Step 5290 : loss 255755.859 ; validation-accuracy: 0.400870502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5300 : loss 842288.438 ; validation-accuracy: 0.400743544\n",
      "Step 5310 : loss 688656.062 ; validation-accuracy: 0.399772525\n",
      "Step 5320 : loss 334369.594 ; validation-accuracy: 0.399374127\n",
      "Step 5330 : loss 1114329.38 ; validation-accuracy: 0.3998245\n",
      "Step 5340 : loss 558720.625 ; validation-accuracy: 0.40056932\n",
      "Step 5350 : loss 2349453.75 ; validation-accuracy: 0.401433647\n",
      "Step 5360 : loss 399270.188 ; validation-accuracy: 0.401967764\n",
      "Step 5370 : loss 487908.219 ; validation-accuracy: 0.402076602\n",
      "Step 5380 : loss 623419.625 ; validation-accuracy: 0.402084231\n",
      "Step 5390 : loss 292218.344 ; validation-accuracy: 0.402092129\n",
      "Step 5400 : loss 826216.875 ; validation-accuracy: 0.401723236\n",
      "Step 5410 : loss 639135 ; validation-accuracy: 0.400446713\n",
      "Step 5420 : loss 312783.25 ; validation-accuracy: 0.399831653\n",
      "Step 5430 : loss 1083121.38 ; validation-accuracy: 0.400215715\n",
      "Step 5440 : loss 585516.938 ; validation-accuracy: 0.400849\n",
      "Step 5450 : loss 2087671 ; validation-accuracy: 0.401931822\n",
      "Step 5460 : loss 399658.062 ; validation-accuracy: 0.402916253\n",
      "Step 5470 : loss 457369.469 ; validation-accuracy: 0.403146803\n",
      "Step 5480 : loss 599829 ; validation-accuracy: 0.403042287\n",
      "Step 5490 : loss 269575.75 ; validation-accuracy: 0.402932584\n",
      "Step 5500 : loss 807707.562 ; validation-accuracy: 0.402510554\n",
      "Step 5510 : loss 658021.188 ; validation-accuracy: 0.401438475\n",
      "Step 5520 : loss 285061.406 ; validation-accuracy: 0.40112102\n",
      "Step 5530 : loss 935351.312 ; validation-accuracy: 0.401877701\n",
      "Step 5540 : loss 609973.688 ; validation-accuracy: 0.402630597\n",
      "Step 5550 : loss 1731920.75 ; validation-accuracy: 0.403462768\n",
      "Step 5560 : loss 442343.469 ; validation-accuracy: 0.404028058\n",
      "Step 5570 : loss 363637.719 ; validation-accuracy: 0.404351711\n",
      "Step 5580 : loss 517168.688 ; validation-accuracy: 0.404082596\n",
      "Step 5590 : loss 266701.281 ; validation-accuracy: 0.404024631\n",
      "Step 5600 : loss 716417.812 ; validation-accuracy: 0.403701901\n",
      "Step 5610 : loss 672836.062 ; validation-accuracy: 0.402674228\n",
      "Step 5620 : loss 296504.344 ; validation-accuracy: 0.402412236\n",
      "Step 5630 : loss 1030280.12 ; validation-accuracy: 0.403161585\n",
      "Step 5640 : loss 538663.938 ; validation-accuracy: 0.404060781\n",
      "Step 5650 : loss 1811786.25 ; validation-accuracy: 0.40504095\n",
      "Step 5660 : loss 363375.219 ; validation-accuracy: 0.405934095\n",
      "Step 5670 : loss 478989.438 ; validation-accuracy: 0.40629214\n",
      "Step 5680 : loss 682393.938 ; validation-accuracy: 0.406285644\n",
      "Step 5690 : loss 250114.969 ; validation-accuracy: 0.406321585\n",
      "Step 5700 : loss 776316.312 ; validation-accuracy: 0.406184226\n",
      "Step 5710 : loss 555879.188 ; validation-accuracy: 0.404840469\n",
      "Step 5720 : loss 290628.781 ; validation-accuracy: 0.404082417\n",
      "Step 5730 : loss 1070729.25 ; validation-accuracy: 0.404778689\n",
      "Step 5740 : loss 493186.844 ; validation-accuracy: 0.405683845\n",
      "Step 5750 : loss 2207673.5 ; validation-accuracy: 0.406651855\n",
      "Step 5760 : loss 374081.656 ; validation-accuracy: 0.407192349\n",
      "Step 5770 : loss 488918.906 ; validation-accuracy: 0.407096744\n",
      "Step 5780 : loss 749669.375 ; validation-accuracy: 0.406799376\n",
      "Step 5790 : loss 224252.469 ; validation-accuracy: 0.406905919\n",
      "Step 5800 : loss 725073.875 ; validation-accuracy: 0.40673402\n",
      "Step 5810 : loss 587178.312 ; validation-accuracy: 0.406078726\n",
      "Step 5820 : loss 344441.344 ; validation-accuracy: 0.40611583\n",
      "Step 5830 : loss 1081772.62 ; validation-accuracy: 0.40723598\n",
      "Step 5840 : loss 595042.438 ; validation-accuracy: 0.407883942\n",
      "Step 5850 : loss 1663033 ; validation-accuracy: 0.408899963\n",
      "Step 5860 : loss 387833.344 ; validation-accuracy: 0.409792304\n",
      "Step 5870 : loss 518835.562 ; validation-accuracy: 0.410212815\n",
      "Step 5880 : loss 616853.625 ; validation-accuracy: 0.41002652\n",
      "Step 5890 : loss 297042.531 ; validation-accuracy: 0.410329759\n",
      "Step 5900 : loss 711609.812 ; validation-accuracy: 0.410444349\n",
      "Step 5910 : loss 592308.812 ; validation-accuracy: 0.409519196\n",
      "Step 5920 : loss 279101.719 ; validation-accuracy: 0.409306675\n",
      "Step 5930 : loss 1050306.38 ; validation-accuracy: 0.410019428\n",
      "Step 5940 : loss 451955 ; validation-accuracy: 0.410614073\n",
      "Step 5950 : loss 1623317.88 ; validation-accuracy: 0.41136837\n",
      "Step 5960 : loss 402779.75 ; validation-accuracy: 0.412298143\n",
      "Step 5970 : loss 552410.125 ; validation-accuracy: 0.412627131\n",
      "Step 5980 : loss 604238.438 ; validation-accuracy: 0.412057906\n",
      "Step 5990 : loss 249912 ; validation-accuracy: 0.411823332\n",
      "Step 6000 : loss 896027.625 ; validation-accuracy: 0.411622\n",
      "Step 6010 : loss 643090.938 ; validation-accuracy: 0.410671651\n",
      "Step 6020 : loss 340922.312 ; validation-accuracy: 0.410402894\n",
      "Step 6030 : loss 887057.562 ; validation-accuracy: 0.411158681\n",
      "Step 6040 : loss 474563.594 ; validation-accuracy: 0.411836147\n",
      "Step 6050 : loss 2572352.75 ; validation-accuracy: 0.412679762\n",
      "Step 6060 : loss 449373.469 ; validation-accuracy: 0.41358161\n",
      "Step 6070 : loss 420994.219 ; validation-accuracy: 0.413744152\n",
      "Step 6080 : loss 499490.719 ; validation-accuracy: 0.413624763\n",
      "Step 6090 : loss 271495.406 ; validation-accuracy: 0.413335115\n",
      "Step 6100 : loss 803287 ; validation-accuracy: 0.412858754\n",
      "Step 6110 : loss 537923.375 ; validation-accuracy: 0.411539376\n",
      "Step 6120 : loss 240258.75 ; validation-accuracy: 0.411255717\n",
      "Step 6130 : loss 969563.875 ; validation-accuracy: 0.412087023\n",
      "Step 6140 : loss 452576.719 ; validation-accuracy: 0.412735134\n",
      "Step 6150 : loss 1459135.62 ; validation-accuracy: 0.413526118\n",
      "Step 6160 : loss 458119.562 ; validation-accuracy: 0.414008081\n",
      "Step 6170 : loss 539082.688 ; validation-accuracy: 0.413753927\n",
      "Step 6180 : loss 596778.438 ; validation-accuracy: 0.413010091\n",
      "Step 6190 : loss 297532.062 ; validation-accuracy: 0.412784308\n",
      "Step 6200 : loss 733424.438 ; validation-accuracy: 0.412680328\n",
      "Step 6210 : loss 629140.438 ; validation-accuracy: 0.4117136\n",
      "Step 6220 : loss 314476.938 ; validation-accuracy: 0.411280692\n",
      "Step 6230 : loss 1023057.38 ; validation-accuracy: 0.412442237\n",
      "Step 6240 : loss 489606.062 ; validation-accuracy: 0.413428\n",
      "Step 6250 : loss 2023474 ; validation-accuracy: 0.414507329\n",
      "Step 6260 : loss 506516.062 ; validation-accuracy: 0.415503442\n",
      "Step 6270 : loss 577170.188 ; validation-accuracy: 0.415983379\n",
      "Step 6280 : loss 633930.688 ; validation-accuracy: 0.415686816\n",
      "Step 6290 : loss 298639.25 ; validation-accuracy: 0.415452838\n",
      "Step 6300 : loss 873178.188 ; validation-accuracy: 0.415035725\n",
      "Step 6310 : loss 613576.062 ; validation-accuracy: 0.413936973\n",
      "Step 6320 : loss 280369.531 ; validation-accuracy: 0.413850307\n",
      "Step 6330 : loss 1020759.31 ; validation-accuracy: 0.415080845\n",
      "Step 6340 : loss 457615.969 ; validation-accuracy: 0.416147679\n",
      "Step 6350 : loss 2050000.25 ; validation-accuracy: 0.417404592\n",
      "Step 6360 : loss 391293.562 ; validation-accuracy: 0.417975068\n",
      "Step 6370 : loss 386510.719 ; validation-accuracy: 0.417734593\n",
      "Step 6380 : loss 621818.438 ; validation-accuracy: 0.41716516\n",
      "Step 6390 : loss 325971.812 ; validation-accuracy: 0.416935921\n",
      "Step 6400 : loss 827087.375 ; validation-accuracy: 0.416595578\n",
      "Step 6410 : loss 635828.438 ; validation-accuracy: 0.415040553\n",
      "Step 6420 : loss 278912.625 ; validation-accuracy: 0.414377928\n",
      "Step 6430 : loss 905317.875 ; validation-accuracy: 0.415047884\n",
      "Step 6440 : loss 510502.844 ; validation-accuracy: 0.415767074\n",
      "Step 6450 : loss 1801438 ; validation-accuracy: 0.416775823\n",
      "Step 6460 : loss 543189.125 ; validation-accuracy: 0.41733402\n",
      "Step 6470 : loss 547554.812 ; validation-accuracy: 0.417248935\n",
      "Step 6480 : loss 591575.438 ; validation-accuracy: 0.416648924\n",
      "Step 6490 : loss 298229.25 ; validation-accuracy: 0.416502893\n",
      "Step 6500 : loss 784170 ; validation-accuracy: 0.416496038\n",
      "Step 6510 : loss 614297.062 ; validation-accuracy: 0.41544196\n",
      "Step 6520 : loss 344691.438 ; validation-accuracy: 0.415032268\n",
      "Step 6530 : loss 1032695.81 ; validation-accuracy: 0.416369736\n",
      "Step 6540 : loss 592086.938 ; validation-accuracy: 0.417252719\n",
      "Step 6550 : loss 1612127 ; validation-accuracy: 0.417889178\n",
      "Step 6560 : loss 333687.438 ; validation-accuracy: 0.418589234\n",
      "Step 6570 : loss 534176.812 ; validation-accuracy: 0.418758869\n",
      "Step 6580 : loss 669642.562 ; validation-accuracy: 0.418371677\n",
      "Step 6590 : loss 233471.828 ; validation-accuracy: 0.418361545\n",
      "Step 6600 : loss 840032.062 ; validation-accuracy: 0.418526769\n",
      "Step 6610 : loss 633467.375 ; validation-accuracy: 0.417320937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6620 : loss 342635.781 ; validation-accuracy: 0.417123735\n",
      "Step 6630 : loss 940480.125 ; validation-accuracy: 0.417523563\n",
      "Step 6640 : loss 467248.656 ; validation-accuracy: 0.418071091\n",
      "Step 6650 : loss 2099720.5 ; validation-accuracy: 0.41925621\n",
      "Step 6660 : loss 439940.938 ; validation-accuracy: 0.42059797\n",
      "Step 6670 : loss 524872.875 ; validation-accuracy: 0.42084673\n",
      "Step 6680 : loss 599022.375 ; validation-accuracy: 0.420454204\n",
      "Step 6690 : loss 289523.062 ; validation-accuracy: 0.420545101\n",
      "Step 6700 : loss 821111.688 ; validation-accuracy: 0.420696467\n",
      "Step 6710 : loss 584868.062 ; validation-accuracy: 0.420237809\n",
      "Step 6720 : loss 291384.375 ; validation-accuracy: 0.420366466\n",
      "Step 6730 : loss 1068446.12 ; validation-accuracy: 0.421473026\n",
      "Step 6740 : loss 416201.5 ; validation-accuracy: 0.422309041\n",
      "Step 6750 : loss 1651314 ; validation-accuracy: 0.42321825\n",
      "Step 6760 : loss 573837.625 ; validation-accuracy: 0.424205482\n",
      "Step 6770 : loss 553023 ; validation-accuracy: 0.424465\n",
      "Step 6780 : loss 561433.812 ; validation-accuracy: 0.423785746\n",
      "Step 6790 : loss 232037.109 ; validation-accuracy: 0.42351383\n",
      "Step 6800 : loss 786609.812 ; validation-accuracy: 0.423274726\n",
      "Step 6810 : loss 599221.875 ; validation-accuracy: 0.421848416\n",
      "Step 6820 : loss 279685.5 ; validation-accuracy: 0.421239674\n",
      "Step 6830 : loss 806052.812 ; validation-accuracy: 0.421778709\n",
      "Step 6840 : loss 435221.062 ; validation-accuracy: 0.422414124\n",
      "Step 6850 : loss 1651652.88 ; validation-accuracy: 0.423519909\n",
      "Step 6860 : loss 550646.812 ; validation-accuracy: 0.42430523\n",
      "Step 6870 : loss 539051.312 ; validation-accuracy: 0.42427206\n",
      "Step 6880 : loss 682044.438 ; validation-accuracy: 0.423578441\n",
      "Step 6890 : loss 349499.469 ; validation-accuracy: 0.423189\n",
      "Step 6900 : loss 864379.5 ; validation-accuracy: 0.422864556\n",
      "Step 6910 : loss 593536.312 ; validation-accuracy: 0.421942502\n",
      "Step 6920 : loss 276563.344 ; validation-accuracy: 0.422085702\n",
      "Step 6930 : loss 957056.875 ; validation-accuracy: 0.423234344\n",
      "Step 6940 : loss 488896.562 ; validation-accuracy: 0.424496889\n",
      "Step 6950 : loss 1858560.62 ; validation-accuracy: 0.425770402\n",
      "Step 6960 : loss 617991.5 ; validation-accuracy: 0.427283287\n",
      "Step 6970 : loss 595870.312 ; validation-accuracy: 0.427538216\n",
      "Step 6980 : loss 554089.625 ; validation-accuracy: 0.426911384\n",
      "Step 6990 : loss 277303.062 ; validation-accuracy: 0.426273674\n",
      "Step 7000 : loss 717455.125 ; validation-accuracy: 0.425899804\n",
      "Step 7010 : loss 626067.688 ; validation-accuracy: 0.425063\n",
      "Step 7020 : loss 235613.422 ; validation-accuracy: 0.425094843\n",
      "Step 7030 : loss 1165375.25 ; validation-accuracy: 0.426126152\n",
      "Step 7040 : loss 616461.938 ; validation-accuracy: 0.426690608\n",
      "Step 7050 : loss 1787998.75 ; validation-accuracy: 0.427529871\n",
      "Step 7060 : loss 446319.219 ; validation-accuracy: 0.428282201\n",
      "Step 7070 : loss 548075.875 ; validation-accuracy: 0.428134263\n",
      "Step 7080 : loss 634937.062 ; validation-accuracy: 0.427188396\n",
      "Step 7090 : loss 351655.719 ; validation-accuracy: 0.426920593\n",
      "Step 7100 : loss 694339.875 ; validation-accuracy: 0.427209556\n",
      "Step 7110 : loss 432107.906 ; validation-accuracy: 0.42665261\n",
      "Step 7120 : loss 227040.75 ; validation-accuracy: 0.426497757\n",
      "Step 7130 : loss 926111.688 ; validation-accuracy: 0.427403152\n",
      "Step 7140 : loss 447021.469 ; validation-accuracy: 0.428342342\n",
      "Step 7150 : loss 1127417.25 ; validation-accuracy: 0.429560363\n",
      "Step 7160 : loss 406719.344 ; validation-accuracy: 0.430640936\n",
      "Step 7170 : loss 596929.312 ; validation-accuracy: 0.431150496\n",
      "Step 7180 : loss 566143.875 ; validation-accuracy: 0.430673957\n",
      "Step 7190 : loss 222498.609 ; validation-accuracy: 0.430446565\n",
      "Step 7200 : loss 832720.688 ; validation-accuracy: 0.430084\n",
      "Step 7210 : loss 592591.688 ; validation-accuracy: 0.429147899\n",
      "Step 7220 : loss 206468.594 ; validation-accuracy: 0.429058373\n",
      "Step 7230 : loss 965586.625 ; validation-accuracy: 0.430167764\n",
      "Step 7240 : loss 574911.062 ; validation-accuracy: 0.430666447\n",
      "Step 7250 : loss 1629227.12 ; validation-accuracy: 0.43182826\n",
      "Step 7260 : loss 522955.219 ; validation-accuracy: 0.433306336\n",
      "Step 7270 : loss 467746.062 ; validation-accuracy: 0.433643758\n",
      "Step 7280 : loss 636153.875 ; validation-accuracy: 0.43320334\n",
      "Step 7290 : loss 292278.938 ; validation-accuracy: 0.433205307\n",
      "Step 7300 : loss 869699.562 ; validation-accuracy: 0.433521271\n",
      "Step 7310 : loss 632846.5 ; validation-accuracy: 0.432283223\n",
      "Step 7320 : loss 268085.062 ; validation-accuracy: 0.432105601\n",
      "Step 7330 : loss 1053374 ; validation-accuracy: 0.432969391\n",
      "Step 7340 : loss 422826.781 ; validation-accuracy: 0.433180481\n",
      "Step 7350 : loss 1500976 ; validation-accuracy: 0.433894306\n",
      "Step 7360 : loss 440827.719 ; validation-accuracy: 0.435068399\n",
      "Step 7370 : loss 527755.438 ; validation-accuracy: 0.435137033\n",
      "Step 7380 : loss 661535.562 ; validation-accuracy: 0.434509039\n",
      "Step 7390 : loss 219256.156 ; validation-accuracy: 0.434051335\n",
      "Step 7400 : loss 736014 ; validation-accuracy: 0.433757573\n",
      "Step 7410 : loss 692321.125 ; validation-accuracy: 0.432649851\n",
      "Step 7420 : loss 200275.797 ; validation-accuracy: 0.432304\n",
      "Step 7430 : loss 891914.062 ; validation-accuracy: 0.433309346\n",
      "Step 7440 : loss 494376.719 ; validation-accuracy: 0.433495343\n",
      "Step 7450 : loss 2023793.38 ; validation-accuracy: 0.434595108\n",
      "Step 7460 : loss 476587.562 ; validation-accuracy: 0.435764045\n",
      "Step 7470 : loss 545863.125 ; validation-accuracy: 0.435899\n",
      "Step 7480 : loss 483174.719 ; validation-accuracy: 0.435786277\n",
      "Step 7490 : loss 299795.062 ; validation-accuracy: 0.435720086\n",
      "Step 7500 : loss 929776.562 ; validation-accuracy: 0.435616612\n",
      "Step 7510 : loss 609607 ; validation-accuracy: 0.434972763\n",
      "Step 7520 : loss 244803.734 ; validation-accuracy: 0.43499127\n",
      "Step 7530 : loss 872432.062 ; validation-accuracy: 0.435661376\n",
      "Step 7540 : loss 535089.375 ; validation-accuracy: 0.435850501\n",
      "Step 7550 : loss 1439762.38 ; validation-accuracy: 0.4364371\n",
      "Step 7560 : loss 436652.25 ; validation-accuracy: 0.436733\n",
      "Step 7570 : loss 643834.688 ; validation-accuracy: 0.436512\n",
      "Step 7580 : loss 545214.875 ; validation-accuracy: 0.436177194\n",
      "Step 7590 : loss 258655.75 ; validation-accuracy: 0.43573603\n",
      "Step 7600 : loss 803231.125 ; validation-accuracy: 0.435444713\n",
      "Step 7610 : loss 489553.062 ; validation-accuracy: 0.434592\n",
      "Step 7620 : loss 217308.922 ; validation-accuracy: 0.435006082\n",
      "Step 7630 : loss 857696.062 ; validation-accuracy: 0.436174661\n",
      "Step 7640 : loss 527336.875 ; validation-accuracy: 0.436729074\n",
      "Step 7650 : loss 1437154.75 ; validation-accuracy: 0.437743127\n",
      "Step 7660 : loss 472772.594 ; validation-accuracy: 0.4389745\n",
      "Step 7670 : loss 626976.375 ; validation-accuracy: 0.439242691\n",
      "Step 7680 : loss 603866.188 ; validation-accuracy: 0.438967496\n",
      "Step 7690 : loss 335408.656 ; validation-accuracy: 0.438670814\n",
      "Step 7700 : loss 969995.375 ; validation-accuracy: 0.438677311\n",
      "Step 7710 : loss 612432.562 ; validation-accuracy: 0.437989533\n",
      "Step 7720 : loss 243095.172 ; validation-accuracy: 0.437966287\n",
      "Step 7730 : loss 982265.562 ; validation-accuracy: 0.438961387\n",
      "Step 7740 : loss 451485.812 ; validation-accuracy: 0.439571917\n",
      "Step 7750 : loss 1773711.75 ; validation-accuracy: 0.44032234\n",
      "Step 7760 : loss 476915.906 ; validation-accuracy: 0.441264778\n",
      "Step 7770 : loss 610360.562 ; validation-accuracy: 0.441458941\n",
      "Step 7780 : loss 688808.5 ; validation-accuracy: 0.440837026\n",
      "Step 7790 : loss 231119.922 ; validation-accuracy: 0.440369606\n",
      "Step 7800 : loss 831685.688 ; validation-accuracy: 0.439894587\n",
      "Step 7810 : loss 546375 ; validation-accuracy: 0.438390374\n",
      "Step 7820 : loss 215259.297 ; validation-accuracy: 0.438216686\n",
      "Step 7830 : loss 905654.625 ; validation-accuracy: 0.439391911\n",
      "Step 7840 : loss 669925.562 ; validation-accuracy: 0.440165907\n",
      "Step 7850 : loss 1343337.88 ; validation-accuracy: 0.440944076\n",
      "Step 7860 : loss 574026.188 ; validation-accuracy: 0.442177773\n",
      "Step 7870 : loss 655092.688 ; validation-accuracy: 0.442341238\n",
      "Step 7880 : loss 648080.062 ; validation-accuracy: 0.441845745\n",
      "Step 7890 : loss 328861.188 ; validation-accuracy: 0.441484034\n",
      "Step 7900 : loss 792529.125 ; validation-accuracy: 0.441248059\n",
      "Step 7910 : loss 555564.688 ; validation-accuracy: 0.439782619\n",
      "Step 7920 : loss 244373.594 ; validation-accuracy: 0.439400077\n",
      "Step 7930 : loss 887561.312 ; validation-accuracy: 0.440166414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7940 : loss 478554.156 ; validation-accuracy: 0.440625697\n",
      "Step 7950 : loss 1520381 ; validation-accuracy: 0.441542327\n",
      "Step 7960 : loss 523009.781 ; validation-accuracy: 0.442274332\n",
      "Step 7970 : loss 487361.781 ; validation-accuracy: 0.442693293\n",
      "Step 7980 : loss 698230.5 ; validation-accuracy: 0.442594945\n",
      "Step 7990 : loss 289046.562 ; validation-accuracy: 0.442328572\n",
      "Step 8000 : loss 820139.812 ; validation-accuracy: 0.442163944\n",
      "Step 8010 : loss 582886.188 ; validation-accuracy: 0.441504896\n",
      "Step 8020 : loss 324825.156 ; validation-accuracy: 0.441704333\n",
      "Step 8030 : loss 603964.188 ; validation-accuracy: 0.442787\n",
      "Step 8040 : loss 474431.844 ; validation-accuracy: 0.44331786\n",
      "Step 8050 : loss 1824658.38 ; validation-accuracy: 0.444277495\n",
      "Step 8060 : loss 456348.844 ; validation-accuracy: 0.445112944\n",
      "Step 8070 : loss 548662.438 ; validation-accuracy: 0.444841951\n",
      "Step 8080 : loss 568954.125 ; validation-accuracy: 0.443956792\n",
      "Step 8090 : loss 315223.938 ; validation-accuracy: 0.44381389\n",
      "Step 8100 : loss 877021.5 ; validation-accuracy: 0.443928629\n",
      "Step 8110 : loss 546013.438 ; validation-accuracy: 0.443299353\n",
      "Step 8120 : loss 277621.125 ; validation-accuracy: 0.443494707\n",
      "Step 8130 : loss 895210.438 ; validation-accuracy: 0.444572866\n",
      "Step 8140 : loss 430357.156 ; validation-accuracy: 0.445133388\n",
      "Step 8150 : loss 1652039.62 ; validation-accuracy: 0.446053207\n",
      "Step 8160 : loss 439648.594 ; validation-accuracy: 0.446981102\n",
      "Step 8170 : loss 542073.438 ; validation-accuracy: 0.446808815\n",
      "Step 8180 : loss 474637.219 ; validation-accuracy: 0.446169943\n",
      "Step 8190 : loss 311391.031 ; validation-accuracy: 0.44579792\n",
      "Step 8200 : loss 796835.875 ; validation-accuracy: 0.445992142\n",
      "Step 8210 : loss 596875.625 ; validation-accuracy: 0.445040226\n",
      "Step 8220 : loss 244258.766 ; validation-accuracy: 0.444801897\n",
      "Step 8230 : loss 956656.438 ; validation-accuracy: 0.445929587\n",
      "Step 8240 : loss 492642.938 ; validation-accuracy: 0.446102\n",
      "Step 8250 : loss 1.20944e+06 ; validation-accuracy: 0.4468413\n",
      "Step 8260 : loss 454996.906 ; validation-accuracy: 0.448010385\n",
      "Step 8270 : loss 508915.906 ; validation-accuracy: 0.447866797\n",
      "Step 8280 : loss 760236.312 ; validation-accuracy: 0.447014332\n",
      "Step 8290 : loss 250113.5 ; validation-accuracy: 0.446840197\n",
      "Step 8300 : loss 852943.312 ; validation-accuracy: 0.446698427\n",
      "Step 8310 : loss 476351.906 ; validation-accuracy: 0.445680082\n",
      "Step 8320 : loss 233447.609 ; validation-accuracy: 0.445709705\n",
      "Step 8330 : loss 924645 ; validation-accuracy: 0.44674927\n",
      "Step 8340 : loss 580002.625 ; validation-accuracy: 0.447257072\n",
      "Step 8350 : loss 1350870.25 ; validation-accuracy: 0.44800818\n",
      "Step 8360 : loss 517608.844 ; validation-accuracy: 0.449034899\n",
      "Step 8370 : loss 640905.875 ; validation-accuracy: 0.449262381\n",
      "Step 8380 : loss 668624.875 ; validation-accuracy: 0.449234784\n",
      "Step 8390 : loss 409110.75 ; validation-accuracy: 0.449001491\n",
      "Step 8400 : loss 812773.625 ; validation-accuracy: 0.448855132\n",
      "Step 8410 : loss 616005.938 ; validation-accuracy: 0.447454631\n",
      "Step 8420 : loss 180614.781 ; validation-accuracy: 0.447347224\n",
      "Step 8430 : loss 827890.812 ; validation-accuracy: 0.448129326\n",
      "Step 8440 : loss 638513.875 ; validation-accuracy: 0.448513567\n",
      "Step 8450 : loss 1039236.94 ; validation-accuracy: 0.449033916\n",
      "Step 8460 : loss 470669.906 ; validation-accuracy: 0.449977\n",
      "Step 8470 : loss 568289.188 ; validation-accuracy: 0.449848831\n",
      "Step 8480 : loss 674805.562 ; validation-accuracy: 0.44928652\n",
      "Step 8490 : loss 338210.656 ; validation-accuracy: 0.448856235\n",
      "Step 8500 : loss 781311.5 ; validation-accuracy: 0.448599309\n",
      "Step 8510 : loss 552109.75 ; validation-accuracy: 0.447200745\n",
      "Step 8520 : loss 233699.25 ; validation-accuracy: 0.447211206\n",
      "Step 8530 : loss 721004 ; validation-accuracy: 0.447932363\n",
      "Step 8540 : loss 444928 ; validation-accuracy: 0.448217332\n",
      "Step 8550 : loss 1767274.12 ; validation-accuracy: 0.449050039\n",
      "Step 8560 : loss 478043.531 ; validation-accuracy: 0.450139105\n",
      "Step 8570 : loss 454982.719 ; validation-accuracy: 0.450426877\n",
      "Step 8580 : loss 612047 ; validation-accuracy: 0.450025618\n",
      "Step 8590 : loss 273242.688 ; validation-accuracy: 0.449673712\n",
      "Step 8600 : loss 960452.625 ; validation-accuracy: 0.44944483\n",
      "Step 8610 : loss 480549.938 ; validation-accuracy: 0.448400468\n",
      "Step 8620 : loss 222256.75 ; validation-accuracy: 0.448151886\n",
      "Step 8630 : loss 893915.875 ; validation-accuracy: 0.449708194\n",
      "Step 8640 : loss 542215.75 ; validation-accuracy: 0.450403571\n",
      "Step 8650 : loss 1121947.62 ; validation-accuracy: 0.451328754\n",
      "Step 8660 : loss 548556.938 ; validation-accuracy: 0.452161491\n",
      "Step 8670 : loss 681061.438 ; validation-accuracy: 0.452231675\n",
      "Step 8680 : loss 765603 ; validation-accuracy: 0.451908201\n",
      "Step 8690 : loss 273163.781 ; validation-accuracy: 0.451940894\n",
      "Step 8700 : loss 741504.438 ; validation-accuracy: 0.451900244\n",
      "Step 8710 : loss 695076.812 ; validation-accuracy: 0.451252401\n",
      "Step 8720 : loss 279304.156 ; validation-accuracy: 0.451371253\n",
      "Step 8730 : loss 865395.312 ; validation-accuracy: 0.452285528\n",
      "Step 8740 : loss 543819.938 ; validation-accuracy: 0.452757061\n",
      "Step 8750 : loss 1478023.62 ; validation-accuracy: 0.453560382\n",
      "Step 8760 : loss 329608.938 ; validation-accuracy: 0.454293311\n",
      "Step 8770 : loss 635850.062 ; validation-accuracy: 0.45405823\n",
      "Step 8780 : loss 754873.875 ; validation-accuracy: 0.453380108\n",
      "Step 8790 : loss 298802.094 ; validation-accuracy: 0.453013\n",
      "Step 8800 : loss 790847.812 ; validation-accuracy: 0.453106165\n",
      "Step 8810 : loss 574742.125 ; validation-accuracy: 0.452432275\n",
      "Step 8820 : loss 276563.312 ; validation-accuracy: 0.452528894\n",
      "Step 8830 : loss 945185.812 ; validation-accuracy: 0.45308131\n",
      "Step 8840 : loss 337015.75 ; validation-accuracy: 0.453379929\n",
      "Step 8850 : loss 1086369.25 ; validation-accuracy: 0.454548717\n",
      "Step 8860 : loss 417718.562 ; validation-accuracy: 0.455813974\n",
      "Step 8870 : loss 670335.688 ; validation-accuracy: 0.455768257\n",
      "Step 8880 : loss 570647.375 ; validation-accuracy: 0.454738379\n",
      "Step 8890 : loss 303552.969 ; validation-accuracy: 0.454063237\n",
      "Step 8900 : loss 929503.312 ; validation-accuracy: 0.453810781\n",
      "Step 8910 : loss 554004.625 ; validation-accuracy: 0.453067899\n",
      "Step 8920 : loss 246361.344 ; validation-accuracy: 0.453246474\n",
      "Step 8930 : loss 782645.438 ; validation-accuracy: 0.454450816\n",
      "Step 8940 : loss 470574.094 ; validation-accuracy: 0.454878628\n",
      "Step 8950 : loss 1070303.25 ; validation-accuracy: 0.455721647\n",
      "Step 8960 : loss 435511.281 ; validation-accuracy: 0.45653981\n",
      "Step 8970 : loss 461422.562 ; validation-accuracy: 0.456425786\n",
      "Step 8980 : loss 618518.312 ; validation-accuracy: 0.455885679\n",
      "Step 8990 : loss 282738.844 ; validation-accuracy: 0.455468416\n",
      "Step 9000 : loss 880056.938 ; validation-accuracy: 0.455580533\n",
      "Step 9010 : loss 671247.875 ; validation-accuracy: 0.454596281\n",
      "Step 9020 : loss 352367.656 ; validation-accuracy: 0.454656184\n",
      "Step 9030 : loss 662525.938 ; validation-accuracy: 0.455821902\n",
      "Step 9040 : loss 489078.781 ; validation-accuracy: 0.456040144\n",
      "Step 9050 : loss 1220169.25 ; validation-accuracy: 0.45680359\n",
      "Step 9060 : loss 313559.562 ; validation-accuracy: 0.458031327\n",
      "Step 9070 : loss 775600.312 ; validation-accuracy: 0.458251745\n",
      "Step 9080 : loss 727737.375 ; validation-accuracy: 0.457684159\n",
      "Step 9090 : loss 256425.672 ; validation-accuracy: 0.457092345\n",
      "Step 9100 : loss 825142.312 ; validation-accuracy: 0.456564546\n",
      "Step 9110 : loss 639022.875 ; validation-accuracy: 0.455524743\n",
      "Step 9120 : loss 301138.281 ; validation-accuracy: 0.455514878\n",
      "Step 9130 : loss 837030 ; validation-accuracy: 0.456610084\n",
      "Step 9140 : loss 638183.625 ; validation-accuracy: 0.457561076\n",
      "Step 9150 : loss 1089186.88 ; validation-accuracy: 0.458618134\n",
      "Step 9160 : loss 422033.656 ; validation-accuracy: 0.459222168\n",
      "Step 9170 : loss 472078.281 ; validation-accuracy: 0.45874998\n",
      "Step 9180 : loss 491437.594 ; validation-accuracy: 0.458183527\n",
      "Step 9190 : loss 246870.328 ; validation-accuracy: 0.457954764\n",
      "Step 9200 : loss 844961.5 ; validation-accuracy: 0.457536697\n",
      "Step 9210 : loss 616325.875 ; validation-accuracy: 0.456947625\n",
      "Step 9220 : loss 300320.219 ; validation-accuracy: 0.457169533\n",
      "Step 9230 : loss 920932.125 ; validation-accuracy: 0.458299756\n",
      "Step 9240 : loss 429845.281 ; validation-accuracy: 0.459160864\n",
      "Step 9250 : loss 1732027 ; validation-accuracy: 0.46006307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9260 : loss 422243.656 ; validation-accuracy: 0.461487114\n",
      "Step 9270 : loss 572637.875 ; validation-accuracy: 0.462127924\n",
      "Step 9280 : loss 513895.062 ; validation-accuracy: 0.461931378\n",
      "Step 9290 : loss 305366.531 ; validation-accuracy: 0.461612\n",
      "Step 9300 : loss 809239.5 ; validation-accuracy: 0.46085155\n",
      "Step 9310 : loss 509431.594 ; validation-accuracy: 0.459416032\n",
      "Step 9320 : loss 247485.219 ; validation-accuracy: 0.459002167\n",
      "Step 9330 : loss 703888 ; validation-accuracy: 0.459267825\n",
      "Step 9340 : loss 394822.438 ; validation-accuracy: 0.45912379\n",
      "Step 9350 : loss 1183743.75 ; validation-accuracy: 0.46015656\n",
      "Step 9360 : loss 458288.062 ; validation-accuracy: 0.461519957\n",
      "Step 9370 : loss 549942.875 ; validation-accuracy: 0.461225212\n",
      "Step 9380 : loss 548789.188 ; validation-accuracy: 0.460498512\n",
      "Step 9390 : loss 322590.812 ; validation-accuracy: 0.460134923\n",
      "Step 9400 : loss 812207.688 ; validation-accuracy: 0.460253477\n",
      "Step 9410 : loss 512839.156 ; validation-accuracy: 0.45966506\n",
      "Step 9420 : loss 188774.047 ; validation-accuracy: 0.45977813\n",
      "Step 9430 : loss 907423.875 ; validation-accuracy: 0.460437983\n",
      "Step 9440 : loss 689312.688 ; validation-accuracy: 0.460556984\n",
      "Step 9450 : loss 843351.438 ; validation-accuracy: 0.461083174\n",
      "Step 9460 : loss 401043.219 ; validation-accuracy: 0.461618423\n",
      "Step 9470 : loss 571371.375 ; validation-accuracy: 0.461187303\n",
      "Step 9480 : loss 585909.938 ; validation-accuracy: 0.460374713\n",
      "Step 9490 : loss 238704.406 ; validation-accuracy: 0.459939212\n",
      "Step 9500 : loss 822751.562 ; validation-accuracy: 0.459944785\n",
      "Step 9510 : loss 542973.625 ; validation-accuracy: 0.459306061\n",
      "Step 9520 : loss 205693.156 ; validation-accuracy: 0.459402025\n",
      "Step 9530 : loss 735654.438 ; validation-accuracy: 0.460461557\n",
      "Step 9540 : loss 549327.125 ; validation-accuracy: 0.461174697\n",
      "Step 9550 : loss 1262885.12 ; validation-accuracy: 0.462028414\n",
      "Step 9560 : loss 442159.688 ; validation-accuracy: 0.462984353\n",
      "Step 9570 : loss 592331.375 ; validation-accuracy: 0.462920129\n",
      "Step 9580 : loss 757808.375 ; validation-accuracy: 0.461800873\n",
      "Step 9590 : loss 318205.781 ; validation-accuracy: 0.461181432\n",
      "Step 9600 : loss 914561.5 ; validation-accuracy: 0.460883975\n",
      "Step 9610 : loss 631555.062 ; validation-accuracy: 0.45999077\n",
      "Step 9620 : loss 280955.656 ; validation-accuracy: 0.459671766\n",
      "Step 9630 : loss 783888.188 ; validation-accuracy: 0.460276872\n",
      "Step 9640 : loss 259001.734 ; validation-accuracy: 0.460654795\n",
      "Step 9650 : loss 1647122.75 ; validation-accuracy: 0.461893618\n",
      "Step 9660 : loss 398167.5 ; validation-accuracy: 0.463384688\n",
      "Step 9670 : loss 480687.469 ; validation-accuracy: 0.463848591\n",
      "Step 9680 : loss 532825.188 ; validation-accuracy: 0.463269025\n",
      "Step 9690 : loss 254068.969 ; validation-accuracy: 0.462724954\n",
      "Step 9700 : loss 940703.438 ; validation-accuracy: 0.462705463\n",
      "Step 9710 : loss 470179.5 ; validation-accuracy: 0.462403297\n",
      "Step 9720 : loss 262051.297 ; validation-accuracy: 0.462950349\n",
      "Step 9730 : loss 811813.375 ; validation-accuracy: 0.464219749\n",
      "Step 9740 : loss 396146.062 ; validation-accuracy: 0.464614719\n",
      "Step 9750 : loss 1368600.12 ; validation-accuracy: 0.465310335\n",
      "Step 9760 : loss 476851.812 ; validation-accuracy: 0.466458648\n",
      "Step 9770 : loss 682766.062 ; validation-accuracy: 0.466499329\n",
      "Step 9780 : loss 684652.688 ; validation-accuracy: 0.465852857\n",
      "Step 9790 : loss 268752.594 ; validation-accuracy: 0.465949\n",
      "Step 9800 : loss 864626.188 ; validation-accuracy: 0.465841413\n",
      "Step 9810 : loss 438513.156 ; validation-accuracy: 0.465222865\n",
      "Step 9820 : loss 256456.578 ; validation-accuracy: 0.465390563\n",
      "Step 9830 : loss 795040.438 ; validation-accuracy: 0.466320872\n",
      "Step 9840 : loss 398358.406 ; validation-accuracy: 0.46648246\n",
      "Step 9850 : loss 1345421.62 ; validation-accuracy: 0.467072606\n",
      "Step 9860 : loss 534301.75 ; validation-accuracy: 0.468080938\n",
      "Step 9870 : loss 654930.312 ; validation-accuracy: 0.468084961\n",
      "Step 9880 : loss 544265.625 ; validation-accuracy: 0.467017531\n",
      "Step 9890 : loss 335845.438 ; validation-accuracy: 0.466465\n",
      "Step 9900 : loss 755340.125 ; validation-accuracy: 0.466263056\n",
      "Step 9910 : loss 497496.031 ; validation-accuracy: 0.465059817\n",
      "Step 9920 : loss 202775.203 ; validation-accuracy: 0.465236753\n",
      "Step 9930 : loss 842882.688 ; validation-accuracy: 0.466212273\n",
      "Step 9940 : loss 403815.75 ; validation-accuracy: 0.466702163\n",
      "Step 9950 : loss 1222601.25 ; validation-accuracy: 0.467815131\n",
      "Step 9960 : loss 494546.594 ; validation-accuracy: 0.46937871\n",
      "Step 9970 : loss 618483.5 ; validation-accuracy: 0.469620794\n",
      "Step 9980 : loss 979498.875 ; validation-accuracy: 0.46909669\n",
      "Step 9990 : loss 319641.938 ; validation-accuracy: 0.46902138\n",
      "Step 10000 : loss 851445.188 ; validation-accuracy: 0.468428105\n",
      "Step 10010 : loss 669186 ; validation-accuracy: 0.467252612\n",
      "Step 10020 : loss 359539.781 ; validation-accuracy: 0.467057496\n",
      "Step 10030 : loss 576384.125 ; validation-accuracy: 0.468209\n",
      "Step 10040 : loss 456377.688 ; validation-accuracy: 0.468578428\n",
      "Step 10050 : loss 1068829 ; validation-accuracy: 0.469388038\n",
      "Step 10060 : loss 387226.156 ; validation-accuracy: 0.470642805\n",
      "Step 10070 : loss 589425.938 ; validation-accuracy: 0.470966935\n",
      "Step 10080 : loss 561716.688 ; validation-accuracy: 0.47046417\n",
      "Step 10090 : loss 321371.938 ; validation-accuracy: 0.470360696\n",
      "Step 10100 : loss 1016804.56 ; validation-accuracy: 0.470347762\n",
      "Step 10110 : loss 519754.719 ; validation-accuracy: 0.469185621\n",
      "Step 10120 : loss 194758.516 ; validation-accuracy: 0.46941185\n",
      "Step 10130 : loss 904806.062 ; validation-accuracy: 0.470496356\n",
      "Step 10140 : loss 369056.719 ; validation-accuracy: 0.470649838\n",
      "Step 10150 : loss 1284952.75 ; validation-accuracy: 0.471184313\n",
      "Step 10160 : loss 452281.438 ; validation-accuracy: 0.471907943\n",
      "Step 10170 : loss 578782.125 ; validation-accuracy: 0.471502602\n",
      "Step 10180 : loss 626870.062 ; validation-accuracy: 0.470287055\n",
      "Step 10190 : loss 247592.891 ; validation-accuracy: 0.47003153\n",
      "Step 10200 : loss 873254.5 ; validation-accuracy: 0.469833136\n",
      "Step 10210 : loss 470140.656 ; validation-accuracy: 0.469540954\n",
      "Step 10220 : loss 318819.562 ; validation-accuracy: 0.469903469\n",
      "Step 10230 : loss 792685.375 ; validation-accuracy: 0.470746875\n",
      "Step 10240 : loss 444270.438 ; validation-accuracy: 0.471189231\n",
      "Step 10250 : loss 1494121.88 ; validation-accuracy: 0.471433818\n",
      "Step 10260 : loss 447841.656 ; validation-accuracy: 0.471944571\n",
      "Step 10270 : loss 663805.938 ; validation-accuracy: 0.471634269\n",
      "Step 10280 : loss 706495.625 ; validation-accuracy: 0.471078455\n",
      "Step 10290 : loss 225462.75 ; validation-accuracy: 0.471169055\n",
      "Step 10300 : loss 823525 ; validation-accuracy: 0.470973402\n",
      "Step 10310 : loss 449412.219 ; validation-accuracy: 0.470130801\n",
      "Step 10320 : loss 305610.844 ; validation-accuracy: 0.470488429\n",
      "Step 10330 : loss 565339.125 ; validation-accuracy: 0.471472979\n",
      "Step 10340 : loss 371921.844 ; validation-accuracy: 0.471468747\n",
      "Step 10350 : loss 972901.812 ; validation-accuracy: 0.471855223\n",
      "Step 10360 : loss 538576 ; validation-accuracy: 0.472693294\n",
      "Step 10370 : loss 696465.125 ; validation-accuracy: 0.472606301\n",
      "Step 10380 : loss 679752.312 ; validation-accuracy: 0.471937954\n",
      "Step 10390 : loss 240263.281 ; validation-accuracy: 0.471630156\n",
      "Step 10400 : loss 901724.562 ; validation-accuracy: 0.471634\n",
      "Step 10410 : loss 441168.219 ; validation-accuracy: 0.471236348\n",
      "Step 10420 : loss 230786.375 ; validation-accuracy: 0.471730471\n",
      "Step 10430 : loss 888945.125 ; validation-accuracy: 0.473627\n",
      "Step 10440 : loss 445788.938 ; validation-accuracy: 0.474431694\n",
      "Step 10450 : loss 925262.812 ; validation-accuracy: 0.475338876\n",
      "Step 10460 : loss 666988.938 ; validation-accuracy: 0.47655955\n",
      "Step 10470 : loss 673972.562 ; validation-accuracy: 0.476008832\n",
      "Step 10480 : loss 665119.688 ; validation-accuracy: 0.475056738\n",
      "Step 10490 : loss 348651.844 ; validation-accuracy: 0.474634647\n",
      "Step 10500 : loss 894100 ; validation-accuracy: 0.474246085\n",
      "Step 10510 : loss 463318.969 ; validation-accuracy: 0.47336781\n",
      "Step 10520 : loss 238283.891 ; validation-accuracy: 0.472952634\n",
      "Step 10530 : loss 658324.125 ; validation-accuracy: 0.473858535\n",
      "Step 10540 : loss 462896.031 ; validation-accuracy: 0.474290967\n",
      "Step 10550 : loss 900505.062 ; validation-accuracy: 0.47519505\n",
      "Step 10560 : loss 442570.531 ; validation-accuracy: 0.476187378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10570 : loss 713953.438 ; validation-accuracy: 0.476228893\n",
      "Step 10580 : loss 489421.281 ; validation-accuracy: 0.475013673\n",
      "Step 10590 : loss 254067.469 ; validation-accuracy: 0.474745214\n",
      "Step 10600 : loss 960997.875 ; validation-accuracy: 0.47515595\n",
      "Step 10610 : loss 415309.281 ; validation-accuracy: 0.474463165\n",
      "Step 10620 : loss 151484.484 ; validation-accuracy: 0.475040644\n",
      "Step 10630 : loss 738302.562 ; validation-accuracy: 0.475964487\n",
      "Step 10640 : loss 404172.156 ; validation-accuracy: 0.476787418\n",
      "Step 10650 : loss 1385867.25 ; validation-accuracy: 0.477854669\n",
      "Step 10660 : loss 343130.5 ; validation-accuracy: 0.479262948\n",
      "Step 10670 : loss 569744.375 ; validation-accuracy: 0.479148865\n",
      "Step 10680 : loss 763437.625 ; validation-accuracy: 0.478284478\n",
      "Step 10690 : loss 214206.219 ; validation-accuracy: 0.478076756\n",
      "Step 10700 : loss 873251 ; validation-accuracy: 0.478123635\n",
      "Step 10710 : loss 647429.312 ; validation-accuracy: 0.476650476\n",
      "Step 10720 : loss 183703.75 ; validation-accuracy: 0.476071715\n",
      "Step 10730 : loss 717407.5 ; validation-accuracy: 0.476782858\n",
      "Step 10740 : loss 518613.219 ; validation-accuracy: 0.477091312\n",
      "Step 10750 : loss 903327.312 ; validation-accuracy: 0.477840602\n",
      "Step 10760 : loss 314389.469 ; validation-accuracy: 0.479005277\n",
      "Step 10770 : loss 671582.562 ; validation-accuracy: 0.479348\n",
      "Step 10780 : loss 673237.875 ; validation-accuracy: 0.478819847\n",
      "Step 10790 : loss 269679.531 ; validation-accuracy: 0.478537381\n",
      "Step 10800 : loss 882534.375 ; validation-accuracy: 0.478088737\n",
      "Step 10810 : loss 715738.688 ; validation-accuracy: 0.477019042\n",
      "Step 10820 : loss 305940.844 ; validation-accuracy: 0.47709924\n",
      "Step 10830 : loss 794360.938 ; validation-accuracy: 0.477935493\n",
      "Step 10840 : loss 519950.281 ; validation-accuracy: 0.478247136\n",
      "Step 10850 : loss 1084318.62 ; validation-accuracy: 0.479435176\n",
      "Step 10860 : loss 728417.688 ; validation-accuracy: 0.481074691\n",
      "Step 10870 : loss 521100.438 ; validation-accuracy: 0.480851769\n",
      "Step 10880 : loss 771687.125 ; validation-accuracy: 0.479715109\n",
      "Step 10890 : loss 288631.219 ; validation-accuracy: 0.478986979\n",
      "Step 10900 : loss 1007658.94 ; validation-accuracy: 0.479063034\n",
      "Step 10910 : loss 486292.594 ; validation-accuracy: 0.478544593\n",
      "Step 10920 : loss 172775.469 ; validation-accuracy: 0.478380322\n",
      "Step 10930 : loss 811779.312 ; validation-accuracy: 0.479210883\n",
      "Step 10940 : loss 431683.656 ; validation-accuracy: 0.479478896\n",
      "Step 10950 : loss 1055575 ; validation-accuracy: 0.480546594\n",
      "Step 10960 : loss 440164.344 ; validation-accuracy: 0.482202739\n",
      "Step 10970 : loss 627369.375 ; validation-accuracy: 0.482576877\n",
      "Step 10980 : loss 671416.312 ; validation-accuracy: 0.482055306\n",
      "Step 10990 : loss 293455.156 ; validation-accuracy: 0.482124388\n",
      "Step 11000 : loss 835390 ; validation-accuracy: 0.482261896\n",
      "Step 11010 : loss 555748 ; validation-accuracy: 0.481768966\n",
      "Step 11020 : loss 344445.969 ; validation-accuracy: 0.482246816\n",
      "Step 11030 : loss 770871.438 ; validation-accuracy: 0.483484596\n",
      "Step 11040 : loss 457490.469 ; validation-accuracy: 0.483975172\n",
      "Step 11050 : loss 1019595.31 ; validation-accuracy: 0.484804451\n",
      "Step 11060 : loss 548216.812 ; validation-accuracy: 0.48575443\n",
      "Step 11070 : loss 565112.562 ; validation-accuracy: 0.485215664\n",
      "Step 11080 : loss 736559.625 ; validation-accuracy: 0.484065771\n",
      "Step 11090 : loss 315483.094 ; validation-accuracy: 0.483580083\n",
      "Step 11100 : loss 928209.125 ; validation-accuracy: 0.483319163\n",
      "Step 11110 : loss 622855.188 ; validation-accuracy: 0.482762337\n",
      "Step 11120 : loss 227060.234 ; validation-accuracy: 0.483000576\n",
      "Step 11130 : loss 692598.125 ; validation-accuracy: 0.484536767\n",
      "Step 11140 : loss 464986.656 ; validation-accuracy: 0.485211551\n",
      "Step 11150 : loss 946823.5 ; validation-accuracy: 0.485964149\n",
      "Step 11160 : loss 509676.656 ; validation-accuracy: 0.487044215\n",
      "Step 11170 : loss 613507.438 ; validation-accuracy: 0.486746609\n",
      "Step 11180 : loss 591034.875 ; validation-accuracy: 0.485773742\n",
      "Step 11190 : loss 385280.281 ; validation-accuracy: 0.485264242\n",
      "Step 11200 : loss 949317.875 ; validation-accuracy: 0.485395432\n",
      "Step 11210 : loss 699906.812 ; validation-accuracy: 0.485242039\n",
      "Step 11220 : loss 209838.109 ; validation-accuracy: 0.485740036\n",
      "Step 11230 : loss 840961.562 ; validation-accuracy: 0.486667633\n",
      "Step 11240 : loss 323123.562 ; validation-accuracy: 0.487380177\n",
      "Step 11250 : loss 1189365.12 ; validation-accuracy: 0.488046288\n",
      "Step 11260 : loss 409749.594 ; validation-accuracy: 0.488650918\n",
      "Step 11270 : loss 573834.5 ; validation-accuracy: 0.488049835\n",
      "Step 11280 : loss 641946.562 ; validation-accuracy: 0.487074137\n",
      "Step 11290 : loss 331337.656 ; validation-accuracy: 0.486686677\n",
      "Step 11300 : loss 932070.312 ; validation-accuracy: 0.486843228\n",
      "Step 11310 : loss 647079.312 ; validation-accuracy: 0.485959828\n",
      "Step 11320 : loss 370247.031 ; validation-accuracy: 0.486060709\n",
      "Step 11330 : loss 616597.125 ; validation-accuracy: 0.486646593\n",
      "Step 11340 : loss 445415.344 ; validation-accuracy: 0.486743152\n",
      "Step 11350 : loss 1025762.69 ; validation-accuracy: 0.487656236\n",
      "Step 11360 : loss 455732.062 ; validation-accuracy: 0.489272386\n",
      "Step 11370 : loss 572557.438 ; validation-accuracy: 0.489646256\n",
      "Step 11380 : loss 601493.875 ; validation-accuracy: 0.489271343\n",
      "Step 11390 : loss 332747 ; validation-accuracy: 0.489025325\n",
      "Step 11400 : loss 1054128.75 ; validation-accuracy: 0.488618404\n",
      "Step 11410 : loss 533178.312 ; validation-accuracy: 0.488117218\n",
      "Step 11420 : loss 251644.953 ; validation-accuracy: 0.488280654\n",
      "Step 11430 : loss 795827.188 ; validation-accuracy: 0.488673151\n",
      "Step 11440 : loss 471412.969 ; validation-accuracy: 0.488624185\n",
      "Step 11450 : loss 1710584.12 ; validation-accuracy: 0.489301354\n",
      "Step 11460 : loss 629668.375 ; validation-accuracy: 0.48994416\n",
      "Step 11470 : loss 718463.688 ; validation-accuracy: 0.489317536\n",
      "Step 11480 : loss 777857.812 ; validation-accuracy: 0.488152117\n",
      "Step 11490 : loss 426774.219 ; validation-accuracy: 0.487579495\n",
      "Step 11500 : loss 885672.625 ; validation-accuracy: 0.486899585\n",
      "Step 11510 : loss 598354.312 ; validation-accuracy: 0.485991478\n",
      "Step 11520 : loss 240615.703 ; validation-accuracy: 0.486550868\n",
      "Step 11530 : loss 783047.062 ; validation-accuracy: 0.488163531\n",
      "Step 11540 : loss 509379.781 ; validation-accuracy: 0.489142835\n",
      "Step 11550 : loss 893281.625 ; validation-accuracy: 0.49023205\n",
      "Step 11560 : loss 505039.781 ; validation-accuracy: 0.491237551\n",
      "Step 11570 : loss 602727.312 ; validation-accuracy: 0.491416544\n",
      "Step 11580 : loss 559390.688 ; validation-accuracy: 0.490501463\n",
      "Step 11590 : loss 267660.906 ; validation-accuracy: 0.49031961\n",
      "Step 11600 : loss 970014.312 ; validation-accuracy: 0.490530133\n",
      "Step 11610 : loss 535874.688 ; validation-accuracy: 0.490279794\n",
      "Step 11620 : loss 320062.062 ; validation-accuracy: 0.49034977\n",
      "Step 11630 : loss 806047.125 ; validation-accuracy: 0.491462588\n",
      "Step 11640 : loss 584963.375 ; validation-accuracy: 0.491811663\n",
      "Step 11650 : loss 1216688 ; validation-accuracy: 0.492005199\n",
      "Step 11660 : loss 507076.438 ; validation-accuracy: 0.492161125\n",
      "Step 11670 : loss 597301.438 ; validation-accuracy: 0.491644919\n",
      "Step 11680 : loss 736453 ; validation-accuracy: 0.490510017\n",
      "Step 11690 : loss 173812.531 ; validation-accuracy: 0.490076125\n",
      "Step 11700 : loss 981594.188 ; validation-accuracy: 0.490202218\n",
      "Step 11710 : loss 549081.875 ; validation-accuracy: 0.489126384\n",
      "Step 11720 : loss 238991.141 ; validation-accuracy: 0.489239424\n",
      "Step 11730 : loss 795700.875 ; validation-accuracy: 0.490926474\n",
      "Step 11740 : loss 481758.031 ; validation-accuracy: 0.491712898\n",
      "Step 11750 : loss 1375908.62 ; validation-accuracy: 0.492460549\n",
      "Step 11760 : loss 395757.938 ; validation-accuracy: 0.493404746\n",
      "Step 11770 : loss 586910.312 ; validation-accuracy: 0.493669927\n",
      "Step 11780 : loss 741839.125 ; validation-accuracy: 0.492939293\n",
      "Step 11790 : loss 452645.781 ; validation-accuracy: 0.49258402\n",
      "Step 11800 : loss 893084.188 ; validation-accuracy: 0.492249072\n",
      "Step 11810 : loss 641057.562 ; validation-accuracy: 0.491410553\n",
      "Step 11820 : loss 204037.828 ; validation-accuracy: 0.491408706\n",
      "Step 11830 : loss 848430.812 ; validation-accuracy: 0.492417544\n",
      "Step 11840 : loss 348930.344 ; validation-accuracy: 0.493351728\n",
      "Step 11850 : loss 1033127.44 ; validation-accuracy: 0.494725406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 11860 : loss 386706.812 ; validation-accuracy: 0.495935\n",
      "Step 11870 : loss 501285.562 ; validation-accuracy: 0.4956384\n",
      "Step 11880 : loss 585255.688 ; validation-accuracy: 0.494728923\n",
      "Step 11890 : loss 316692.906 ; validation-accuracy: 0.494195253\n",
      "Step 11900 : loss 826112.688 ; validation-accuracy: 0.493989885\n",
      "Step 11910 : loss 542906.312 ; validation-accuracy: 0.493556082\n",
      "Step 11920 : loss 236970.828 ; validation-accuracy: 0.493759751\n",
      "Step 11930 : loss 684123.375 ; validation-accuracy: 0.494686663\n",
      "Step 11940 : loss 631136.312 ; validation-accuracy: 0.495065093\n",
      "Step 11950 : loss 405659.562 ; validation-accuracy: 0.495625854\n",
      "Step 11960 : loss 394790.844 ; validation-accuracy: 0.496346176\n",
      "Step 11970 : loss 538253.188 ; validation-accuracy: 0.496144712\n",
      "Step 11980 : loss 889971.812 ; validation-accuracy: 0.495065093\n",
      "Step 11990 : loss 266131.406 ; validation-accuracy: 0.494397759\n",
      "Step 12000 : loss 871790.812 ; validation-accuracy: 0.493561506\n",
      "Step 12010 : loss 532184.812 ; validation-accuracy: 0.492287219\n",
      "Step 12020 : loss 413172.969 ; validation-accuracy: 0.492438883\n",
      "Step 12030 : loss 676759.688 ; validation-accuracy: 0.493264705\n",
      "Step 12040 : loss 402821.281 ; validation-accuracy: 0.493535697\n",
      "Step 12050 : loss 822418.312 ; validation-accuracy: 0.494423211\n",
      "Step 12060 : loss 268155.156 ; validation-accuracy: 0.495589405\n",
      "Step 12070 : loss 600417.375 ; validation-accuracy: 0.495571673\n",
      "Step 12080 : loss 775672.375 ; validation-accuracy: 0.494988799\n",
      "Step 12090 : loss 284097.344 ; validation-accuracy: 0.494868398\n",
      "Step 12100 : loss 930675.125 ; validation-accuracy: 0.494687825\n",
      "Step 12110 : loss 586372.812 ; validation-accuracy: 0.494233251\n",
      "Step 12120 : loss 157313.625 ; validation-accuracy: 0.494870305\n",
      "Step 12130 : loss 761273.062 ; validation-accuracy: 0.496244222\n",
      "Step 12140 : loss 417477.844 ; validation-accuracy: 0.496728927\n",
      "Step 12150 : loss 717915.812 ; validation-accuracy: 0.497252703\n",
      "Step 12160 : loss 648035.438 ; validation-accuracy: 0.497812092\n",
      "Step 12170 : loss 603220.938 ; validation-accuracy: 0.497582346\n",
      "Step 12180 : loss 633697.312 ; validation-accuracy: 0.49640274\n",
      "Step 12190 : loss 445158.906 ; validation-accuracy: 0.496105045\n",
      "Step 12200 : loss 890081.312 ; validation-accuracy: 0.495642364\n",
      "Step 12210 : loss 592648.562 ; validation-accuracy: 0.495139152\n",
      "Step 12220 : loss 147399.234 ; validation-accuracy: 0.495530903\n",
      "Step 12230 : loss 885143.562 ; validation-accuracy: 0.49655968\n",
      "Step 12240 : loss 323402.812 ; validation-accuracy: 0.497192413\n",
      "Step 12250 : loss 1276979 ; validation-accuracy: 0.498130202\n",
      "Step 12260 : loss 359659.562 ; validation-accuracy: 0.499137342\n",
      "Step 12270 : loss 731112 ; validation-accuracy: 0.498834819\n",
      "Step 12280 : loss 652578.375 ; validation-accuracy: 0.497753441\n",
      "Step 12290 : loss 183605.328 ; validation-accuracy: 0.497055888\n",
      "Step 12300 : loss 1005364.94 ; validation-accuracy: 0.496618032\n",
      "Step 12310 : loss 628449.312 ; validation-accuracy: 0.496988028\n",
      "Step 12320 : loss 290850.688 ; validation-accuracy: 0.497277379\n",
      "Step 12330 : loss 796385.5 ; validation-accuracy: 0.498784661\n",
      "Step 12340 : loss 392782.562 ; validation-accuracy: 0.499130547\n",
      "Step 12350 : loss 885525.875 ; validation-accuracy: 0.49966234\n",
      "Step 12360 : loss 394162.969 ; validation-accuracy: 0.500479817\n",
      "Step 12370 : loss 510781.219 ; validation-accuracy: 0.49988842\n",
      "Step 12380 : loss 724439.375 ; validation-accuracy: 0.498673439\n",
      "Step 12390 : loss 324542.812 ; validation-accuracy: 0.498097301\n",
      "Step 12400 : loss 851377.125 ; validation-accuracy: 0.497485578\n",
      "Step 12410 : loss 573366.562 ; validation-accuracy: 0.49649474\n",
      "Step 12420 : loss 184020.75 ; validation-accuracy: 0.496367872\n",
      "Step 12430 : loss 799336.125 ; validation-accuracy: 0.497762144\n",
      "Step 12440 : loss 404513 ; validation-accuracy: 0.498694837\n",
      "Step 12450 : loss 1050372.88 ; validation-accuracy: 0.499833047\n",
      "Step 12460 : loss 406730.562 ; validation-accuracy: 0.500888646\n",
      "Step 12470 : loss 557574 ; validation-accuracy: 0.500628829\n",
      "Step 12480 : loss 685690.438 ; validation-accuracy: 0.499870688\n",
      "Step 12490 : loss 273693.625 ; validation-accuracy: 0.499857336\n",
      "Step 12500 : loss 856725.062 ; validation-accuracy: 0.500073254\n",
      "Step 12510 : loss 614327.625 ; validation-accuracy: 0.499351799\n",
      "Step 12520 : loss 261087.203 ; validation-accuracy: 0.499233723\n",
      "Step 12530 : loss 854908.125 ; validation-accuracy: 0.500077844\n",
      "Step 12540 : loss 583228.812 ; validation-accuracy: 0.500910938\n",
      "Step 12550 : loss 1231317.88 ; validation-accuracy: 0.501434565\n",
      "Step 12560 : loss 456907.656 ; validation-accuracy: 0.502326608\n",
      "Step 12570 : loss 478527 ; validation-accuracy: 0.501842737\n",
      "Step 12580 : loss 645698.375 ; validation-accuracy: 0.500499725\n",
      "Step 12590 : loss 331571.156 ; validation-accuracy: 0.499728888\n",
      "Step 12600 : loss 938409.125 ; validation-accuracy: 0.499403894\n",
      "Step 12610 : loss 507692.5 ; validation-accuracy: 0.499342144\n",
      "Step 12620 : loss 189621.922 ; validation-accuracy: 0.499769747\n",
      "Step 12630 : loss 581175.875 ; validation-accuracy: 0.500438094\n",
      "Step 12640 : loss 271635.812 ; validation-accuracy: 0.501101136\n",
      "Step 12650 : loss 750230.812 ; validation-accuracy: 0.502079725\n",
      "Step 12660 : loss 440464.312 ; validation-accuracy: 0.503201723\n",
      "Step 12670 : loss 629397.938 ; validation-accuracy: 0.503380597\n",
      "Step 12680 : loss 784791.562 ; validation-accuracy: 0.502639294\n",
      "Step 12690 : loss 292849.562 ; validation-accuracy: 0.501998603\n",
      "Step 12700 : loss 927061.688 ; validation-accuracy: 0.501731038\n",
      "Step 12710 : loss 384415.062 ; validation-accuracy: 0.501588464\n",
      "Step 12720 : loss 194074 ; validation-accuracy: 0.502046\n",
      "Step 12730 : loss 634863.438 ; validation-accuracy: 0.502767205\n",
      "Step 12740 : loss 499006.406 ; validation-accuracy: 0.502962112\n",
      "Step 12750 : loss 990500.062 ; validation-accuracy: 0.503684103\n",
      "Step 12760 : loss 471655.031 ; validation-accuracy: 0.50503397\n",
      "Step 12770 : loss 618954.125 ; validation-accuracy: 0.504437149\n",
      "Step 12780 : loss 870113.938 ; validation-accuracy: 0.502854168\n",
      "Step 12790 : loss 225746.219 ; validation-accuracy: 0.501686037\n",
      "Step 12800 : loss 928432.688 ; validation-accuracy: 0.501538873\n",
      "Step 12810 : loss 787977.938 ; validation-accuracy: 0.501361\n",
      "Step 12820 : loss 267204.625 ; validation-accuracy: 0.501889706\n",
      "Step 12830 : loss 713379.875 ; validation-accuracy: 0.503501832\n",
      "Step 12840 : loss 527608.625 ; validation-accuracy: 0.503987074\n",
      "Step 12850 : loss 781550.375 ; validation-accuracy: 0.504840434\n",
      "Step 12860 : loss 427033.219 ; validation-accuracy: 0.505777359\n",
      "Step 12870 : loss 672182.875 ; validation-accuracy: 0.505428791\n",
      "Step 12880 : loss 890563.875 ; validation-accuracy: 0.504142642\n",
      "Step 12890 : loss 300177.844 ; validation-accuracy: 0.503816485\n",
      "Step 12900 : loss 893036.938 ; validation-accuracy: 0.503556252\n",
      "Step 12910 : loss 530431.812 ; validation-accuracy: 0.502688289\n",
      "Step 12920 : loss 254494.219 ; validation-accuracy: 0.502699792\n",
      "Step 12930 : loss 592949.375 ; validation-accuracy: 0.503898501\n",
      "Step 12940 : loss 431505.656 ; validation-accuracy: 0.504641771\n",
      "Step 12950 : loss 1376734.75 ; validation-accuracy: 0.505148292\n",
      "Step 12960 : loss 406230.594 ; validation-accuracy: 0.505700052\n",
      "Step 12970 : loss 517261.5 ; validation-accuracy: 0.504980206\n",
      "Step 12980 : loss 787488.562 ; validation-accuracy: 0.503503799\n",
      "Step 12990 : loss 242218 ; validation-accuracy: 0.503327489\n",
      "Step 13000 : loss 789075.938 ; validation-accuracy: 0.503685951\n",
      "Step 13010 : loss 430943.156 ; validation-accuracy: 0.503670335\n",
      "Step 13020 : loss 175236.109 ; validation-accuracy: 0.504024208\n",
      "Step 13030 : loss 853539.812 ; validation-accuracy: 0.505010486\n",
      "Step 13040 : loss 342469.844 ; validation-accuracy: 0.505605936\n",
      "Step 13050 : loss 1221030.38 ; validation-accuracy: 0.506297827\n",
      "Step 13060 : loss 689976.625 ; validation-accuracy: 0.506767154\n",
      "Step 13070 : loss 479401.219 ; validation-accuracy: 0.506184042\n",
      "Step 13080 : loss 953397.625 ; validation-accuracy: 0.505456865\n",
      "Step 13090 : loss 239936.469 ; validation-accuracy: 0.50513339\n",
      "Step 13100 : loss 784100.125 ; validation-accuracy: 0.504824221\n",
      "Step 13110 : loss 555879.562 ; validation-accuracy: 0.504487813\n",
      "Step 13120 : loss 102329.742 ; validation-accuracy: 0.505210757\n",
      "Step 13130 : loss 579467.875 ; validation-accuracy: 0.506365359\n",
      "Step 13140 : loss 383138.281 ; validation-accuracy: 0.50677985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13150 : loss 908493.562 ; validation-accuracy: 0.507365227\n",
      "Step 13160 : loss 634179.625 ; validation-accuracy: 0.508078933\n",
      "Step 13170 : loss 659372.625 ; validation-accuracy: 0.50807327\n",
      "Step 13180 : loss 624709.5 ; validation-accuracy: 0.50688386\n",
      "Step 13190 : loss 285672.656 ; validation-accuracy: 0.506102264\n",
      "Step 13200 : loss 975868.625 ; validation-accuracy: 0.506137252\n",
      "Step 13210 : loss 397857.938 ; validation-accuracy: 0.505478\n",
      "Step 13220 : loss 305461.656 ; validation-accuracy: 0.50594461\n",
      "Step 13230 : loss 623829.125 ; validation-accuracy: 0.506914794\n",
      "Step 13240 : loss 355999.562 ; validation-accuracy: 0.507270575\n",
      "Step 13250 : loss 1113355.88 ; validation-accuracy: 0.507824183\n",
      "Step 13260 : loss 429494.031 ; validation-accuracy: 0.50841248\n",
      "Step 13270 : loss 432650.469 ; validation-accuracy: 0.507889\n",
      "Step 13280 : loss 795459.5 ; validation-accuracy: 0.506445\n",
      "Step 13290 : loss 317985.406 ; validation-accuracy: 0.505959511\n",
      "Step 13300 : loss 913392.688 ; validation-accuracy: 0.505676568\n",
      "Step 13310 : loss 562904.312 ; validation-accuracy: 0.505457\n",
      "Step 13320 : loss 127429.227 ; validation-accuracy: 0.506167889\n",
      "Step 13330 : loss 866639.125 ; validation-accuracy: 0.506797969\n",
      "Step 13340 : loss 378527.719 ; validation-accuracy: 0.506621599\n",
      "Step 13350 : loss 1122688.75 ; validation-accuracy: 0.506662905\n",
      "Step 13360 : loss 434635.656 ; validation-accuracy: 0.507216036\n",
      "Step 13370 : loss 416036.25 ; validation-accuracy: 0.506609797\n",
      "Step 13380 : loss 514463.188 ; validation-accuracy: 0.505297065\n",
      "Step 13390 : loss 379183.906 ; validation-accuracy: 0.505075693\n",
      "Step 13400 : loss 971527.875 ; validation-accuracy: 0.505444169\n",
      "Step 13410 : loss 713732.625 ; validation-accuracy: 0.505056262\n",
      "Step 13420 : loss 209411.391 ; validation-accuracy: 0.505428672\n",
      "Step 13430 : loss 585040.938 ; validation-accuracy: 0.506649\n",
      "Step 13440 : loss 385715.031 ; validation-accuracy: 0.507046402\n",
      "Step 13450 : loss 575067.875 ; validation-accuracy: 0.507387638\n",
      "Step 13460 : loss 341059.156 ; validation-accuracy: 0.507530808\n",
      "Step 13470 : loss 579410.688 ; validation-accuracy: 0.50639689\n",
      "Step 13480 : loss 956787.438 ; validation-accuracy: 0.5046947\n",
      "Step 13490 : loss 335369.844 ; validation-accuracy: 0.504103959\n",
      "Step 13500 : loss 892704.188 ; validation-accuracy: 0.504541874\n",
      "Step 13510 : loss 481511.469 ; validation-accuracy: 0.504493475\n",
      "Step 13520 : loss 281731.844 ; validation-accuracy: 0.505037308\n",
      "Step 13530 : loss 831251.062 ; validation-accuracy: 0.505975842\n",
      "Step 13540 : loss 332289.781 ; validation-accuracy: 0.5060395\n",
      "Step 13550 : loss 1155551.62 ; validation-accuracy: 0.5064255\n",
      "Step 13560 : loss 426486.75 ; validation-accuracy: 0.507981241\n",
      "Step 13570 : loss 626896.875 ; validation-accuracy: 0.507331848\n",
      "Step 13580 : loss 674546.938 ; validation-accuracy: 0.505730748\n",
      "Step 13590 : loss 266857.344 ; validation-accuracy: 0.505381107\n",
      "Step 13600 : loss 1.01233e+06 ; validation-accuracy: 0.505069554\n",
      "Step 13610 : loss 514880.938 ; validation-accuracy: 0.504252493\n",
      "Step 13620 : loss 177011.156 ; validation-accuracy: 0.504675746\n",
      "Step 13630 : loss 803099.688 ; validation-accuracy: 0.505933821\n",
      "Step 13640 : loss 513994.156 ; validation-accuracy: 0.506603122\n",
      "Step 13650 : loss 1133888.25 ; validation-accuracy: 0.5076406\n",
      "Step 13660 : loss 415520.688 ; validation-accuracy: 0.508049905\n",
      "Step 13670 : loss 520368.062 ; validation-accuracy: 0.506592572\n",
      "Step 13680 : loss 708938.5 ; validation-accuracy: 0.504527092\n",
      "Step 13690 : loss 196018.328 ; validation-accuracy: 0.504246593\n",
      "Step 13700 : loss 814979.625 ; validation-accuracy: 0.504843\n",
      "Step 13710 : loss 770157.625 ; validation-accuracy: 0.504545212\n",
      "Step 13720 : loss 431601.062 ; validation-accuracy: 0.504794359\n",
      "Step 13730 : loss 768076.312 ; validation-accuracy: 0.50580138\n",
      "Step 13740 : loss 506551.906 ; validation-accuracy: 0.506059408\n",
      "Step 13750 : loss 577406.625 ; validation-accuracy: 0.506385148\n",
      "Step 13760 : loss 469711 ; validation-accuracy: 0.50664866\n",
      "Step 13770 : loss 526349.125 ; validation-accuracy: 0.506033242\n",
      "Step 13780 : loss 747948.062 ; validation-accuracy: 0.504804313\n",
      "Step 13790 : loss 289945.281 ; validation-accuracy: 0.50479871\n",
      "Step 13800 : loss 933698.812 ; validation-accuracy: 0.505697489\n",
      "Step 13810 : loss 595649.625 ; validation-accuracy: 0.505811036\n",
      "Step 13820 : loss 344493.312 ; validation-accuracy: 0.506484926\n",
      "Step 13830 : loss 554871.688 ; validation-accuracy: 0.507526696\n",
      "Step 13840 : loss 368204.781 ; validation-accuracy: 0.508178473\n",
      "Step 13850 : loss 576263.875 ; validation-accuracy: 0.50862813\n",
      "Step 13860 : loss 578144.938 ; validation-accuracy: 0.508845448\n",
      "Step 13870 : loss 682957.562 ; validation-accuracy: 0.507876813\n",
      "Step 13880 : loss 789701.562 ; validation-accuracy: 0.50614\n",
      "Step 13890 : loss 334865.5 ; validation-accuracy: 0.50564909\n",
      "Step 13900 : loss 756011.562 ; validation-accuracy: 0.50558269\n",
      "Step 13910 : loss 783391.375 ; validation-accuracy: 0.505974174\n",
      "Step 13920 : loss 214705.219 ; validation-accuracy: 0.506547511\n",
      "Step 13930 : loss 619941.438 ; validation-accuracy: 0.50734973\n",
      "Step 13940 : loss 313515.312 ; validation-accuracy: 0.507379115\n",
      "Step 13950 : loss 948509.875 ; validation-accuracy: 0.507873356\n",
      "Step 13960 : loss 544673.875 ; validation-accuracy: 0.50884068\n",
      "Step 13970 : loss 391193.469 ; validation-accuracy: 0.508071423\n",
      "Step 13980 : loss 730325.188 ; validation-accuracy: 0.506429672\n",
      "Step 13990 : loss 333853.062 ; validation-accuracy: 0.506141782\n",
      "Step 14000 : loss 776043.938 ; validation-accuracy: 0.506193042\n",
      "Step 14010 : loss 449684.969 ; validation-accuracy: 0.505783796\n",
      "Step 14020 : loss 296742.469 ; validation-accuracy: 0.50568676\n",
      "Step 14030 : loss 521268.688 ; validation-accuracy: 0.506956935\n",
      "Step 14040 : loss 531475 ; validation-accuracy: 0.507812083\n",
      "Step 14050 : loss 824085.562 ; validation-accuracy: 0.509005904\n",
      "Step 14060 : loss 938839.562 ; validation-accuracy: 0.508938134\n",
      "Step 14070 : loss 403723.281 ; validation-accuracy: 0.506769359\n",
      "Step 14080 : loss 914543.188 ; validation-accuracy: 0.504258633\n",
      "Step 14090 : loss 321514 ; validation-accuracy: 0.503600836\n",
      "Step 14100 : loss 969946.5 ; validation-accuracy: 0.503909\n",
      "Step 14110 : loss 403946 ; validation-accuracy: 0.503218651\n",
      "Step 14120 : loss 300967.062 ; validation-accuracy: 0.503801107\n",
      "Step 14130 : loss 774412.562 ; validation-accuracy: 0.506309867\n",
      "Step 14140 : loss 401554.906 ; validation-accuracy: 0.507382691\n",
      "Step 14150 : loss 897326.688 ; validation-accuracy: 0.508608818\n",
      "Step 14160 : loss 555256.312 ; validation-accuracy: 0.509498596\n",
      "Step 14170 : loss 528835.625 ; validation-accuracy: 0.508424\n",
      "Step 14180 : loss 737229.438 ; validation-accuracy: 0.507338285\n",
      "Step 14190 : loss 235494.109 ; validation-accuracy: 0.507349789\n",
      "Step 14200 : loss 862862.438 ; validation-accuracy: 0.507192612\n",
      "Step 14210 : loss 376016.156 ; validation-accuracy: 0.506015301\n",
      "Step 14220 : loss 230517.203 ; validation-accuracy: 0.506262422\n",
      "Step 14230 : loss 787895.375 ; validation-accuracy: 0.507577\n",
      "Step 14240 : loss 320021.812 ; validation-accuracy: 0.508044958\n",
      "Step 14250 : loss 1210597 ; validation-accuracy: 0.508784711\n",
      "Step 14260 : loss 597159.25 ; validation-accuracy: 0.509981\n",
      "Step 14270 : loss 564035.562 ; validation-accuracy: 0.509689689\n",
      "Step 14280 : loss 704605.688 ; validation-accuracy: 0.508401275\n",
      "Step 14290 : loss 321528.531 ; validation-accuracy: 0.508235276\n",
      "Step 14300 : loss 899633.062 ; validation-accuracy: 0.508654296\n",
      "Step 14310 : loss 692784.562 ; validation-accuracy: 0.508266211\n",
      "Step 14320 : loss 185499 ; validation-accuracy: 0.508831263\n",
      "Step 14330 : loss 747503.375 ; validation-accuracy: 0.509617031\n",
      "Step 14340 : loss 309646.906 ; validation-accuracy: 0.509691596\n",
      "Step 14350 : loss 650491.812 ; validation-accuracy: 0.509899378\n",
      "Step 14360 : loss 539095.375 ; validation-accuracy: 0.510333657\n",
      "Step 14370 : loss 543762.312 ; validation-accuracy: 0.509463072\n",
      "Step 14380 : loss 929616.938 ; validation-accuracy: 0.507935107\n",
      "Step 14390 : loss 335154.906 ; validation-accuracy: 0.507606\n",
      "Step 14400 : loss 878135.625 ; validation-accuracy: 0.507946372\n",
      "Step 14410 : loss 378618.688 ; validation-accuracy: 0.507773399\n",
      "Step 14420 : loss 283773.812 ; validation-accuracy: 0.508592427\n",
      "Step 14430 : loss 560000.5 ; validation-accuracy: 0.510283589\n",
      "Step 14440 : loss 312927.844 ; validation-accuracy: 0.510863781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 14450 : loss 1438491.62 ; validation-accuracy: 0.511461\n",
      "Step 14460 : loss 445055.562 ; validation-accuracy: 0.51213479\n",
      "Step 14470 : loss 565039.312 ; validation-accuracy: 0.51118958\n",
      "Step 14480 : loss 599295 ; validation-accuracy: 0.508694172\n",
      "Step 14490 : loss 333332.562 ; validation-accuracy: 0.50757426\n",
      "Step 14500 : loss 946502.375 ; validation-accuracy: 0.506727517\n",
      "Step 14510 : loss 734854.438 ; validation-accuracy: 0.506831706\n",
      "Step 14520 : loss 166128.25 ; validation-accuracy: 0.507322192\n",
      "Step 14530 : loss 715749.438 ; validation-accuracy: 0.508806765\n",
      "Step 14540 : loss 370584 ; validation-accuracy: 0.509461641\n",
      "Step 14550 : loss 991391.5 ; validation-accuracy: 0.510083377\n",
      "Step 14560 : loss 390070.406 ; validation-accuracy: 0.51056242\n",
      "Step 14570 : loss 678130.688 ; validation-accuracy: 0.509683669\n",
      "Step 14580 : loss 768688.438 ; validation-accuracy: 0.508343458\n",
      "Step 14590 : loss 472756.094 ; validation-accuracy: 0.508559823\n",
      "Step 14600 : loss 843494.438 ; validation-accuracy: 0.509190083\n",
      "Step 14610 : loss 509045.594 ; validation-accuracy: 0.509074748\n",
      "Step 14620 : loss 186882 ; validation-accuracy: 0.509584725\n",
      "Step 14630 : loss 741930 ; validation-accuracy: 0.510699093\n",
      "Step 14640 : loss 414947.156 ; validation-accuracy: 0.511399508\n",
      "Step 14650 : loss 694494.875 ; validation-accuracy: 0.512125969\n",
      "Step 14660 : loss 328083.438 ; validation-accuracy: 0.513293624\n",
      "Step 14670 : loss 609649.812 ; validation-accuracy: 0.512313664\n",
      "Step 14680 : loss 686142.312 ; validation-accuracy: 0.51070565\n",
      "Step 14690 : loss 267775.844 ; validation-accuracy: 0.510149837\n",
      "Step 14700 : loss 768906.875 ; validation-accuracy: 0.509905159\n",
      "Step 14710 : loss 404153.562 ; validation-accuracy: 0.509277523\n",
      "Step 14720 : loss 175124.516 ; validation-accuracy: 0.510497093\n",
      "Step 14730 : loss 710509.562 ; validation-accuracy: 0.511643171\n",
      "Step 14740 : loss 449999.531 ; validation-accuracy: 0.51151216\n",
      "Step 14750 : loss 458381.719 ; validation-accuracy: 0.51184535\n",
      "Step 14760 : loss 399045.344 ; validation-accuracy: 0.512607157\n",
      "Step 14770 : loss 677358 ; validation-accuracy: 0.51176995\n",
      "Step 14780 : loss 701557.188 ; validation-accuracy: 0.510585487\n",
      "Step 14790 : loss 474196.344 ; validation-accuracy: 0.510082841\n",
      "Step 14800 : loss 913412.312 ; validation-accuracy: 0.509983897\n",
      "Step 14810 : loss 463125.812 ; validation-accuracy: 0.50939852\n",
      "Step 14820 : loss 177365.922 ; validation-accuracy: 0.50950706\n",
      "Step 14830 : loss 720659.125 ; validation-accuracy: 0.509968221\n",
      "Step 14840 : loss 354086.562 ; validation-accuracy: 0.510065079\n",
      "Step 14850 : loss 684958.812 ; validation-accuracy: 0.510656\n",
      "Step 14860 : loss 471593.219 ; validation-accuracy: 0.511261284\n",
      "Step 14870 : loss 562657.812 ; validation-accuracy: 0.50986743\n",
      "Step 14880 : loss 807971.5 ; validation-accuracy: 0.507670522\n",
      "Step 14890 : loss 397889.344 ; validation-accuracy: 0.507072747\n",
      "Step 14900 : loss 839326.438 ; validation-accuracy: 0.507234\n",
      "Step 14910 : loss 697477.5 ; validation-accuracy: 0.507394433\n",
      "Step 14920 : loss 150437.016 ; validation-accuracy: 0.508595705\n",
      "Step 14930 : loss 648475 ; validation-accuracy: 0.510380208\n",
      "Step 14940 : loss 387000.781 ; validation-accuracy: 0.510288596\n",
      "Step 14950 : loss 525781.812 ; validation-accuracy: 0.510983706\n",
      "Step 14960 : loss 360803 ; validation-accuracy: 0.512012839\n",
      "Step 14970 : loss 667455.125 ; validation-accuracy: 0.511211395\n",
      "Step 14980 : loss 575078.562 ; validation-accuracy: 0.509651721\n",
      "Step 14990 : loss 313286.781 ; validation-accuracy: 0.509246111\n",
      "Step 15000 : loss 899959.5 ; validation-accuracy: 0.508828163\n",
      "Step 15010 : loss 489703.219 ; validation-accuracy: 0.508981\n",
      "Step 15020 : loss 278176.188 ; validation-accuracy: 0.509819388\n",
      "Step 15030 : loss 699187 ; validation-accuracy: 0.511628866\n",
      "Step 15040 : loss 503414.219 ; validation-accuracy: 0.512429118\n",
      "Step 15050 : loss 672734.938 ; validation-accuracy: 0.513312101\n",
      "Step 15060 : loss 478897.938 ; validation-accuracy: 0.514122963\n",
      "Step 15070 : loss 692916.312 ; validation-accuracy: 0.512863159\n",
      "Step 15080 : loss 845846.312 ; validation-accuracy: 0.51089561\n",
      "Step 15090 : loss 249360.969 ; validation-accuracy: 0.510859728\n",
      "Step 15100 : loss 998669 ; validation-accuracy: 0.511467338\n",
      "Step 15110 : loss 805346.375 ; validation-accuracy: 0.511502504\n",
      "Step 15120 : loss 267388.406 ; validation-accuracy: 0.512134969\n",
      "Step 15130 : loss 461257.656 ; validation-accuracy: 0.513714\n",
      "Step 15140 : loss 642588.562 ; validation-accuracy: 0.514492631\n",
      "Step 15150 : loss 788739.625 ; validation-accuracy: 0.51503861\n",
      "Step 15160 : loss 680143.375 ; validation-accuracy: 0.515753508\n",
      "Step 15170 : loss 674759.625 ; validation-accuracy: 0.514713168\n",
      "Step 15180 : loss 433396.938 ; validation-accuracy: 0.513109684\n",
      "Step 15190 : loss 287692.406 ; validation-accuracy: 0.513028681\n",
      "Step 15200 : loss 907824.625 ; validation-accuracy: 0.513406396\n",
      "Step 15210 : loss 605674.625 ; validation-accuracy: 0.512747645\n",
      "Step 15220 : loss 336994.188 ; validation-accuracy: 0.51270628\n",
      "Step 15230 : loss 539688.625 ; validation-accuracy: 0.513576746\n",
      "Step 15240 : loss 522213.344 ; validation-accuracy: 0.51386857\n",
      "Step 15250 : loss 1065905.75 ; validation-accuracy: 0.514617205\n",
      "Step 15260 : loss 451538.094 ; validation-accuracy: 0.515083313\n",
      "Step 15270 : loss 558206.438 ; validation-accuracy: 0.5144068\n",
      "Step 15280 : loss 609988 ; validation-accuracy: 0.513395548\n",
      "Step 15290 : loss 489071.156 ; validation-accuracy: 0.514031589\n",
      "Step 15300 : loss 859814.938 ; validation-accuracy: 0.514480412\n",
      "Step 15310 : loss 604102.5 ; validation-accuracy: 0.514810681\n",
      "Step 15320 : loss 244085.844 ; validation-accuracy: 0.516276956\n",
      "Step 15330 : loss 632210.562 ; validation-accuracy: 0.517096937\n",
      "Step 15340 : loss 417569.281 ; validation-accuracy: 0.516714931\n",
      "Step 15350 : loss 486193.281 ; validation-accuracy: 0.517146587\n",
      "Step 15360 : loss 457345.938 ; validation-accuracy: 0.517827\n",
      "Step 15370 : loss 673959 ; validation-accuracy: 0.517290592\n",
      "Step 15380 : loss 807943.5 ; validation-accuracy: 0.516014397\n",
      "Step 15390 : loss 358295.75 ; validation-accuracy: 0.515539646\n",
      "Step 15400 : loss 947366.625 ; validation-accuracy: 0.515383482\n",
      "Step 15410 : loss 471325.438 ; validation-accuracy: 0.515110493\n",
      "Step 15420 : loss 187543.172 ; validation-accuracy: 0.515171766\n",
      "Step 15430 : loss 821373.875 ; validation-accuracy: 0.516512334\n",
      "Step 15440 : loss 417217.656 ; validation-accuracy: 0.516837358\n",
      "Step 15450 : loss 1041778.88 ; validation-accuracy: 0.517659307\n",
      "Step 15460 : loss 461227.562 ; validation-accuracy: 0.518847525\n",
      "Step 15470 : loss 688659.562 ; validation-accuracy: 0.518203\n",
      "Step 15480 : loss 821084.438 ; validation-accuracy: 0.516506433\n",
      "Step 15490 : loss 319130.344 ; validation-accuracy: 0.516609251\n",
      "Step 15500 : loss 1077453.12 ; validation-accuracy: 0.516958714\n",
      "Step 15510 : loss 479026.219 ; validation-accuracy: 0.516867399\n",
      "Step 15520 : loss 319430.531 ; validation-accuracy: 0.517872393\n",
      "Step 15530 : loss 600562.375 ; validation-accuracy: 0.519874811\n",
      "Step 15540 : loss 376653.188 ; validation-accuracy: 0.520668924\n",
      "Step 15550 : loss 611497.188 ; validation-accuracy: 0.521247864\n",
      "Step 15560 : loss 400323.75 ; validation-accuracy: 0.521534324\n",
      "Step 15570 : loss 464393.219 ; validation-accuracy: 0.520637393\n",
      "Step 15580 : loss 745626 ; validation-accuracy: 0.518725216\n",
      "Step 15590 : loss 346392.094 ; validation-accuracy: 0.518359423\n",
      "Step 15600 : loss 836163.375 ; validation-accuracy: 0.518285513\n",
      "Step 15610 : loss 577907.125 ; validation-accuracy: 0.517944813\n",
      "Step 15620 : loss 234898.375 ; validation-accuracy: 0.518841863\n",
      "Step 15630 : loss 510483.844 ; validation-accuracy: 0.520324826\n",
      "Step 15640 : loss 673941.125 ; validation-accuracy: 0.521064281\n",
      "Step 15650 : loss 996796.938 ; validation-accuracy: 0.52184391\n",
      "Step 15660 : loss 528907.562 ; validation-accuracy: 0.522161603\n",
      "Step 15670 : loss 574009.375 ; validation-accuracy: 0.521417916\n",
      "Step 15680 : loss 918300.125 ; validation-accuracy: 0.519609213\n",
      "Step 15690 : loss 405939.219 ; validation-accuracy: 0.519570708\n",
      "Step 15700 : loss 864455.562 ; validation-accuracy: 0.519499719\n",
      "Step 15710 : loss 661669.875 ; validation-accuracy: 0.519704\n",
      "Step 15720 : loss 374138.938 ; validation-accuracy: 0.52045238\n",
      "Step 15730 : loss 649979.125 ; validation-accuracy: 0.521566033\n",
      "Step 15740 : loss 362859.656 ; validation-accuracy: 0.521913886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15750 : loss 670398.812 ; validation-accuracy: 0.52273047\n",
      "Step 15760 : loss 459835.25 ; validation-accuracy: 0.523100078\n",
      "Step 15770 : loss 516971.844 ; validation-accuracy: 0.52191484\n",
      "Step 15780 : loss 629753.5 ; validation-accuracy: 0.519673467\n",
      "Step 15790 : loss 292672.969 ; validation-accuracy: 0.519053102\n",
      "Step 15800 : loss 809675 ; validation-accuracy: 0.519145906\n",
      "Step 15810 : loss 530314.125 ; validation-accuracy: 0.518563747\n",
      "Step 15820 : loss 176393.953 ; validation-accuracy: 0.519673645\n",
      "Step 15830 : loss 774966.5 ; validation-accuracy: 0.521119237\n",
      "Step 15840 : loss 392332.531 ; validation-accuracy: 0.52157259\n",
      "Step 15850 : loss 1276991 ; validation-accuracy: 0.522571564\n",
      "Step 15860 : loss 433008.156 ; validation-accuracy: 0.523301661\n",
      "Step 15870 : loss 510278.156 ; validation-accuracy: 0.522236586\n",
      "Step 15880 : loss 610358.938 ; validation-accuracy: 0.521519482\n",
      "Step 15890 : loss 331740.438 ; validation-accuracy: 0.521270037\n",
      "Step 15900 : loss 857358.938 ; validation-accuracy: 0.52110225\n",
      "Step 15910 : loss 560227.938 ; validation-accuracy: 0.520719111\n",
      "Step 15920 : loss 154654.922 ; validation-accuracy: 0.520707\n",
      "Step 15930 : loss 605803.688 ; validation-accuracy: 0.52112931\n",
      "Step 15940 : loss 432855.062 ; validation-accuracy: 0.520489931\n",
      "Step 15950 : loss 722248.438 ; validation-accuracy: 0.521553159\n",
      "Step 15960 : loss 384379.656 ; validation-accuracy: 0.522668242\n",
      "Step 15970 : loss 385375.938 ; validation-accuracy: 0.5220927\n",
      "Step 15980 : loss 712896.125 ; validation-accuracy: 0.5198282\n",
      "Step 15990 : loss 373647.188 ; validation-accuracy: 0.519418\n",
      "Step 16000 : loss 831492.562 ; validation-accuracy: 0.520195484\n",
      "Step 16010 : loss 517271.75 ; validation-accuracy: 0.520604074\n",
      "Step 16020 : loss 146743.594 ; validation-accuracy: 0.521142662\n",
      "Step 16030 : loss 527493 ; validation-accuracy: 0.521950126\n",
      "Step 16040 : loss 292376.469 ; validation-accuracy: 0.522307277\n",
      "Step 16050 : loss 534442.562 ; validation-accuracy: 0.52322495\n",
      "Step 16060 : loss 545112.125 ; validation-accuracy: 0.52325511\n",
      "Step 16070 : loss 500308.562 ; validation-accuracy: 0.52159\n",
      "Step 16080 : loss 619334.188 ; validation-accuracy: 0.520439506\n",
      "Step 16090 : loss 273187.906 ; validation-accuracy: 0.521282792\n",
      "Step 16100 : loss 787139.375 ; validation-accuracy: 0.521687686\n",
      "Step 16110 : loss 619465.062 ; validation-accuracy: 0.521071911\n",
      "Step 16120 : loss 123246.508 ; validation-accuracy: 0.521314263\n",
      "Step 16130 : loss 507381.688 ; validation-accuracy: 0.522496104\n",
      "Step 16140 : loss 247639.953 ; validation-accuracy: 0.522727311\n",
      "Step 16150 : loss 665264.562 ; validation-accuracy: 0.523368895\n",
      "Step 16160 : loss 423803.75 ; validation-accuracy: 0.52379477\n",
      "Step 16170 : loss 565377.875 ; validation-accuracy: 0.522149801\n",
      "Step 16180 : loss 795928.188 ; validation-accuracy: 0.520034969\n",
      "Step 16190 : loss 229765.391 ; validation-accuracy: 0.519346237\n",
      "Step 16200 : loss 782754.625 ; validation-accuracy: 0.519725204\n",
      "Step 16210 : loss 624671.688 ; validation-accuracy: 0.520561934\n",
      "Step 16220 : loss 302954.406 ; validation-accuracy: 0.522343695\n",
      "Step 16230 : loss 673726 ; validation-accuracy: 0.524018764\n",
      "Step 16240 : loss 316832.531 ; validation-accuracy: 0.525129676\n",
      "Step 16250 : loss 477209.031 ; validation-accuracy: 0.525826812\n",
      "Step 16260 : loss 425578.844 ; validation-accuracy: 0.526009262\n",
      "Step 16270 : loss 818796.438 ; validation-accuracy: 0.524884462\n",
      "Step 16280 : loss 567054.062 ; validation-accuracy: 0.523436904\n",
      "Step 16290 : loss 386525 ; validation-accuracy: 0.523176312\n",
      "Step 16300 : loss 751016.125 ; validation-accuracy: 0.523806155\n",
      "Step 16310 : loss 736417.312 ; validation-accuracy: 0.523078799\n",
      "Step 16320 : loss 350591.5 ; validation-accuracy: 0.523349285\n",
      "Step 16330 : loss 765080.438 ; validation-accuracy: 0.524698138\n",
      "Step 16340 : loss 369882.656 ; validation-accuracy: 0.525047302\n",
      "Step 16350 : loss 430590.438 ; validation-accuracy: 0.526016355\n",
      "Step 16360 : loss 510745.938 ; validation-accuracy: 0.526984572\n",
      "Step 16370 : loss 670325.438 ; validation-accuracy: 0.526762187\n",
      "Step 16380 : loss 709988.5 ; validation-accuracy: 0.525688648\n",
      "Step 16390 : loss 329712.438 ; validation-accuracy: 0.525328457\n",
      "Step 16400 : loss 851366.062 ; validation-accuracy: 0.524807215\n",
      "Step 16410 : loss 559376.375 ; validation-accuracy: 0.524319768\n",
      "Step 16420 : loss 175201.078 ; validation-accuracy: 0.524557829\n",
      "Step 16430 : loss 663278.5 ; validation-accuracy: 0.52539295\n",
      "Step 16440 : loss 499817.031 ; validation-accuracy: 0.526104\n",
      "Step 16450 : loss 837621.188 ; validation-accuracy: 0.526878834\n",
      "Step 16460 : loss 409461.688 ; validation-accuracy: 0.527393639\n",
      "Step 16470 : loss 496924.562 ; validation-accuracy: 0.526292443\n",
      "Step 16480 : loss 774379.375 ; validation-accuracy: 0.524716437\n",
      "Step 16490 : loss 281374.094 ; validation-accuracy: 0.525071204\n",
      "Step 16500 : loss 822003.688 ; validation-accuracy: 0.525953233\n",
      "Step 16510 : loss 697764 ; validation-accuracy: 0.525696754\n",
      "Step 16520 : loss 170150.125 ; validation-accuracy: 0.526311755\n",
      "Step 16530 : loss 741526.875 ; validation-accuracy: 0.528044343\n",
      "Step 16540 : loss 375545.438 ; validation-accuracy: 0.529271901\n",
      "Step 16550 : loss 427033.531 ; validation-accuracy: 0.530368447\n",
      "Step 16560 : loss 462386.938 ; validation-accuracy: 0.530565202\n",
      "Step 16570 : loss 558707.188 ; validation-accuracy: 0.528425097\n",
      "Step 16580 : loss 601871.938 ; validation-accuracy: 0.526522517\n",
      "Step 16590 : loss 200803.891 ; validation-accuracy: 0.526412368\n",
      "Step 16600 : loss 940851.688 ; validation-accuracy: 0.527082205\n",
      "Step 16610 : loss 541224.688 ; validation-accuracy: 0.52665633\n",
      "Step 16620 : loss 275795.281 ; validation-accuracy: 0.527263224\n",
      "Step 16630 : loss 688371.875 ; validation-accuracy: 0.528868616\n",
      "Step 16640 : loss 771347.812 ; validation-accuracy: 0.529589951\n",
      "Step 16650 : loss 515586.75 ; validation-accuracy: 0.530401945\n",
      "Step 16660 : loss 542950.562 ; validation-accuracy: 0.531153321\n",
      "Step 16670 : loss 483295.969 ; validation-accuracy: 0.530636668\n",
      "Step 16680 : loss 540203.5 ; validation-accuracy: 0.529567361\n",
      "Step 16690 : loss 247611.391 ; validation-accuracy: 0.529573679\n",
      "Step 16700 : loss 894846.062 ; validation-accuracy: 0.52985096\n",
      "Step 16710 : loss 301138.156 ; validation-accuracy: 0.529700518\n",
      "Step 16720 : loss 179798.016 ; validation-accuracy: 0.530546904\n",
      "Step 16730 : loss 516335.156 ; validation-accuracy: 0.531594872\n",
      "Step 16740 : loss 393514.312 ; validation-accuracy: 0.531446815\n",
      "Step 16750 : loss 474377.688 ; validation-accuracy: 0.531537175\n",
      "Step 16760 : loss 431980 ; validation-accuracy: 0.531899571\n",
      "Step 16770 : loss 625161.875 ; validation-accuracy: 0.531200171\n",
      "Step 16780 : loss 865761.688 ; validation-accuracy: 0.530127347\n",
      "Step 16790 : loss 314440.219 ; validation-accuracy: 0.530236125\n",
      "Step 16800 : loss 856634.438 ; validation-accuracy: 0.530805349\n",
      "Step 16810 : loss 523138.969 ; validation-accuracy: 0.530463\n",
      "Step 16820 : loss 176867.75 ; validation-accuracy: 0.530768037\n",
      "Step 16830 : loss 667769.625 ; validation-accuracy: 0.531422436\n",
      "Step 16840 : loss 407410.688 ; validation-accuracy: 0.531687438\n",
      "Step 16850 : loss 809246.062 ; validation-accuracy: 0.5321334\n",
      "Step 16860 : loss 400677.5 ; validation-accuracy: 0.532204151\n",
      "Step 16870 : loss 403438.438 ; validation-accuracy: 0.531787574\n",
      "Step 16880 : loss 677201.938 ; validation-accuracy: 0.530061245\n",
      "Step 16890 : loss 324783.062 ; validation-accuracy: 0.529572606\n",
      "Step 16900 : loss 876535 ; validation-accuracy: 0.530034602\n",
      "Step 16910 : loss 540221.562 ; validation-accuracy: 0.52915\n",
      "Step 16920 : loss 244335.531 ; validation-accuracy: 0.529386044\n",
      "Step 16930 : loss 570936.688 ; validation-accuracy: 0.530050695\n",
      "Step 16940 : loss 426752.812 ; validation-accuracy: 0.530563951\n",
      "Step 16950 : loss 576612.062 ; validation-accuracy: 0.531365871\n",
      "Step 16960 : loss 565425.625 ; validation-accuracy: 0.531920373\n",
      "Step 16970 : loss 637996.562 ; validation-accuracy: 0.530268967\n",
      "Step 16980 : loss 704391.375 ; validation-accuracy: 0.52775538\n",
      "Step 16990 : loss 286755.781 ; validation-accuracy: 0.527034879\n",
      "Step 17000 : loss 885905.688 ; validation-accuracy: 0.527130842\n",
      "Step 17010 : loss 548730.5 ; validation-accuracy: 0.527453423\n",
      "Step 17020 : loss 376759.844 ; validation-accuracy: 0.52816689\n",
      "Step 17030 : loss 786229.375 ; validation-accuracy: 0.530428052\n",
      "Step 17040 : loss 436404.781 ; validation-accuracy: 0.531418324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 17050 : loss 694018.562 ; validation-accuracy: 0.532355428\n",
      "Step 17060 : loss 458212.25 ; validation-accuracy: 0.533051848\n",
      "Step 17070 : loss 788467 ; validation-accuracy: 0.532222927\n",
      "Step 17080 : loss 633085.312 ; validation-accuracy: 0.530622721\n",
      "Step 17090 : loss 357105.344 ; validation-accuracy: 0.529844284\n",
      "Step 17100 : loss 953898.562 ; validation-accuracy: 0.52983427\n",
      "Step 17110 : loss 576464 ; validation-accuracy: 0.529900491\n",
      "Step 17120 : loss 152946.719 ; validation-accuracy: 0.531060159\n",
      "Step 17130 : loss 573975.562 ; validation-accuracy: 0.532954812\n",
      "Step 17140 : loss 246078.281 ; validation-accuracy: 0.533421934\n",
      "Step 17150 : loss 410705.469 ; validation-accuracy: 0.533271074\n",
      "Step 17160 : loss 586819.5 ; validation-accuracy: 0.533405304\n",
      "Step 17170 : loss 410128.781 ; validation-accuracy: 0.532796\n",
      "Step 17180 : loss 488288.781 ; validation-accuracy: 0.530412793\n",
      "Step 17190 : loss 417758.156 ; validation-accuracy: 0.530063391\n",
      "Step 17200 : loss 826052.812 ; validation-accuracy: 0.529664516\n",
      "Step 17210 : loss 714387.688 ; validation-accuracy: 0.529236257\n",
      "Step 17220 : loss 142049.438 ; validation-accuracy: 0.529852867\n",
      "Step 17230 : loss 439092.469 ; validation-accuracy: 0.531722188\n",
      "Step 17240 : loss 333669.844 ; validation-accuracy: 0.532351196\n",
      "Step 17250 : loss 995617.562 ; validation-accuracy: 0.533295751\n",
      "Step 17260 : loss 588395.062 ; validation-accuracy: 0.534157634\n",
      "Step 17270 : loss 582566.688 ; validation-accuracy: 0.532846093\n",
      "Step 17280 : loss 741534.5 ; validation-accuracy: 0.530641794\n",
      "Step 17290 : loss 210842.828 ; validation-accuracy: 0.53041023\n",
      "Step 17300 : loss 740013.562 ; validation-accuracy: 0.531353891\n",
      "Step 17310 : loss 569169.688 ; validation-accuracy: 0.531633735\n",
      "Step 17320 : loss 250298.359 ; validation-accuracy: 0.532353\n",
      "Step 17330 : loss 745461.562 ; validation-accuracy: 0.534113169\n",
      "Step 17340 : loss 532327.688 ; validation-accuracy: 0.533912\n",
      "Step 17350 : loss 780959.688 ; validation-accuracy: 0.534042358\n",
      "Step 17360 : loss 419984.406 ; validation-accuracy: 0.53395617\n",
      "Step 17370 : loss 659121.625 ; validation-accuracy: 0.532141924\n",
      "Step 17380 : loss 699142.875 ; validation-accuracy: 0.529458046\n",
      "Step 17390 : loss 259979.906 ; validation-accuracy: 0.528538585\n",
      "Step 17400 : loss 1006206.62 ; validation-accuracy: 0.528940797\n",
      "Step 17410 : loss 403631.406 ; validation-accuracy: 0.529268205\n",
      "Step 17420 : loss 194060.922 ; validation-accuracy: 0.530592442\n",
      "Step 17430 : loss 736814 ; validation-accuracy: 0.532345414\n",
      "Step 17440 : loss 383431.219 ; validation-accuracy: 0.532741308\n",
      "Step 17450 : loss 412107.562 ; validation-accuracy: 0.533174634\n",
      "Step 17460 : loss 472400.312 ; validation-accuracy: 0.533260643\n",
      "Step 17470 : loss 641479.688 ; validation-accuracy: 0.531712\n",
      "Step 17480 : loss 754532 ; validation-accuracy: 0.529671967\n",
      "Step 17490 : loss 294430.094 ; validation-accuracy: 0.52947551\n",
      "Step 17500 : loss 840181.5 ; validation-accuracy: 0.529830277\n",
      "Step 17510 : loss 588765.125 ; validation-accuracy: 0.530287504\n",
      "Step 17520 : loss 190043.125 ; validation-accuracy: 0.530803204\n",
      "Step 17530 : loss 761175.625 ; validation-accuracy: 0.532946348\n",
      "Step 17540 : loss 411247.844 ; validation-accuracy: 0.533631504\n",
      "Step 17550 : loss 775820.188 ; validation-accuracy: 0.534604788\n",
      "Step 17560 : loss 395211.75 ; validation-accuracy: 0.5355165\n",
      "Step 17570 : loss 666816.812 ; validation-accuracy: 0.534374714\n",
      "Step 17580 : loss 595721.375 ; validation-accuracy: 0.532628119\n",
      "Step 17590 : loss 327876.438 ; validation-accuracy: 0.532368422\n",
      "Step 17600 : loss 954410 ; validation-accuracy: 0.532538533\n",
      "Step 17610 : loss 538474.188 ; validation-accuracy: 0.533352911\n",
      "Step 17620 : loss 336795.469 ; validation-accuracy: 0.534420609\n",
      "Step 17630 : loss 434593.062 ; validation-accuracy: 0.535751522\n",
      "Step 17640 : loss 497233.312 ; validation-accuracy: 0.535508633\n",
      "Step 17650 : loss 241417.594 ; validation-accuracy: 0.535035968\n",
      "Step 17660 : loss 364899.406 ; validation-accuracy: 0.53427738\n",
      "Step 17670 : loss 694050.5 ; validation-accuracy: 0.532464147\n",
      "Step 17680 : loss 640891.562 ; validation-accuracy: 0.530467629\n",
      "Step 17690 : loss 291985.812 ; validation-accuracy: 0.531011\n",
      "Step 17700 : loss 960514.5 ; validation-accuracy: 0.532111168\n",
      "Step 17710 : loss 666740.438 ; validation-accuracy: 0.532700539\n",
      "Step 17720 : loss 167766.094 ; validation-accuracy: 0.534695\n",
      "Step 17730 : loss 588277.625 ; validation-accuracy: 0.536286\n",
      "Step 17740 : loss 382239.219 ; validation-accuracy: 0.536968827\n",
      "Step 17750 : loss 404110.062 ; validation-accuracy: 0.5377298\n",
      "Step 17760 : loss 447088.969 ; validation-accuracy: 0.537563324\n",
      "Step 17770 : loss 568849.562 ; validation-accuracy: 0.536160588\n",
      "Step 17780 : loss 853804.688 ; validation-accuracy: 0.534397781\n",
      "Step 17790 : loss 287149.094 ; validation-accuracy: 0.534640849\n",
      "Step 17800 : loss 954230.688 ; validation-accuracy: 0.535316586\n",
      "Step 17810 : loss 431671.812 ; validation-accuracy: 0.535171449\n",
      "Step 17820 : loss 206906.969 ; validation-accuracy: 0.535845757\n",
      "Step 17830 : loss 445992.969 ; validation-accuracy: 0.538191676\n",
      "Step 17840 : loss 266577.844 ; validation-accuracy: 0.53871\n",
      "Step 17850 : loss 620310.188 ; validation-accuracy: 0.539348423\n",
      "Step 17860 : loss 417675.031 ; validation-accuracy: 0.539750934\n",
      "Step 17870 : loss 576723.062 ; validation-accuracy: 0.538208723\n",
      "Step 17880 : loss 759621.625 ; validation-accuracy: 0.535796225\n",
      "Step 17890 : loss 345310.844 ; validation-accuracy: 0.535533309\n",
      "Step 17900 : loss 901188.812 ; validation-accuracy: 0.535994709\n",
      "Step 17910 : loss 513398.219 ; validation-accuracy: 0.535861075\n",
      "Step 17920 : loss 223740.891 ; validation-accuracy: 0.536334515\n",
      "Step 17930 : loss 416106.938 ; validation-accuracy: 0.538053632\n",
      "Step 17940 : loss 670628.562 ; validation-accuracy: 0.538422227\n",
      "Step 17950 : loss 899326.188 ; validation-accuracy: 0.539608657\n",
      "Step 17960 : loss 545532.438 ; validation-accuracy: 0.540087\n",
      "Step 17970 : loss 507889.281 ; validation-accuracy: 0.53826344\n",
      "Step 17980 : loss 840586.062 ; validation-accuracy: 0.536500454\n",
      "Step 17990 : loss 373501.469 ; validation-accuracy: 0.536342144\n",
      "Step 18000 : loss 866513.188 ; validation-accuracy: 0.536206603\n",
      "Step 18010 : loss 546516.688 ; validation-accuracy: 0.535777807\n",
      "Step 18020 : loss 77161.375 ; validation-accuracy: 0.536067\n",
      "Step 18030 : loss 525147.375 ; validation-accuracy: 0.537373483\n",
      "Step 18040 : loss 326503.344 ; validation-accuracy: 0.537581086\n",
      "Step 18050 : loss 744334.062 ; validation-accuracy: 0.5382514\n",
      "Step 18060 : loss 456231.938 ; validation-accuracy: 0.538550854\n",
      "Step 18070 : loss 468912.688 ; validation-accuracy: 0.537525177\n",
      "Step 18080 : loss 884159.375 ; validation-accuracy: 0.535765946\n",
      "Step 18090 : loss 412911.719 ; validation-accuracy: 0.535632253\n",
      "Step 18100 : loss 812235.938 ; validation-accuracy: 0.535853386\n",
      "Step 18110 : loss 554069.375 ; validation-accuracy: 0.535811901\n",
      "Step 18120 : loss 359770.969 ; validation-accuracy: 0.535913169\n",
      "Step 18130 : loss 656003.125 ; validation-accuracy: 0.536317289\n",
      "Step 18140 : loss 286673.656 ; validation-accuracy: 0.535874724\n",
      "Step 18150 : loss 554455.062 ; validation-accuracy: 0.536307693\n",
      "Step 18160 : loss 521733.156 ; validation-accuracy: 0.536830664\n",
      "Step 18170 : loss 529887.875 ; validation-accuracy: 0.535490751\n",
      "Step 18180 : loss 841555.812 ; validation-accuracy: 0.532455683\n",
      "Step 18190 : loss 302500.281 ; validation-accuracy: 0.53224659\n",
      "Step 18200 : loss 809055 ; validation-accuracy: 0.532579482\n",
      "Step 18210 : loss 615771 ; validation-accuracy: 0.533649325\n",
      "Step 18220 : loss 121798.547 ; validation-accuracy: 0.535631418\n",
      "Step 18230 : loss 756246.875 ; validation-accuracy: 0.539029539\n",
      "Step 18240 : loss 290563.156 ; validation-accuracy: 0.539729118\n",
      "Step 18250 : loss 1210406.62 ; validation-accuracy: 0.539639592\n",
      "Step 18260 : loss 402468.781 ; validation-accuracy: 0.539285421\n",
      "Step 18270 : loss 564177.812 ; validation-accuracy: 0.537379622\n",
      "Step 18280 : loss 661692.625 ; validation-accuracy: 0.535487473\n",
      "Step 18290 : loss 265044.688 ; validation-accuracy: 0.535320461\n",
      "Step 18300 : loss 832957.625 ; validation-accuracy: 0.535322428\n",
      "Step 18310 : loss 562174.312 ; validation-accuracy: 0.535793185\n",
      "Step 18320 : loss 142005.875 ; validation-accuracy: 0.536414742\n",
      "Step 18330 : loss 710104.938 ; validation-accuracy: 0.537784755\n",
      "Step 18340 : loss 527334.938 ; validation-accuracy: 0.53871882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 18350 : loss 722507.562 ; validation-accuracy: 0.539833724\n",
      "Step 18360 : loss 427767.031 ; validation-accuracy: 0.540463269\n",
      "Step 18370 : loss 648876 ; validation-accuracy: 0.538653255\n",
      "Step 18380 : loss 652873.375 ; validation-accuracy: 0.536402404\n",
      "Step 18390 : loss 343280.094 ; validation-accuracy: 0.536018074\n",
      "Step 18400 : loss 816345.562 ; validation-accuracy: 0.536675394\n",
      "Step 18410 : loss 484318.75 ; validation-accuracy: 0.536958754\n",
      "Step 18420 : loss 310352.156 ; validation-accuracy: 0.536859095\n",
      "Step 18430 : loss 725706.688 ; validation-accuracy: 0.538579941\n",
      "Step 18440 : loss 280665.125 ; validation-accuracy: 0.538883865\n",
      "Step 18450 : loss 365168.031 ; validation-accuracy: 0.539474249\n",
      "Step 18460 : loss 411643.594 ; validation-accuracy: 0.539734\n",
      "Step 18470 : loss 554971.062 ; validation-accuracy: 0.538849831\n",
      "Step 18480 : loss 863169.312 ; validation-accuracy: 0.536784172\n",
      "Step 18490 : loss 306873.062 ; validation-accuracy: 0.536723077\n",
      "Step 18500 : loss 906676.812 ; validation-accuracy: 0.536315799\n",
      "Step 18510 : loss 553346.438 ; validation-accuracy: 0.536081195\n",
      "Step 18520 : loss 243441.297 ; validation-accuracy: 0.537189245\n",
      "Step 18530 : loss 435833 ; validation-accuracy: 0.53971827\n",
      "Step 18540 : loss 424730.938 ; validation-accuracy: 0.54040134\n",
      "Step 18550 : loss 581156.312 ; validation-accuracy: 0.541139901\n",
      "Step 18560 : loss 677839.688 ; validation-accuracy: 0.541758418\n",
      "Step 18570 : loss 572291.438 ; validation-accuracy: 0.540591\n",
      "Step 18580 : loss 688796.812 ; validation-accuracy: 0.539537191\n",
      "Step 18590 : loss 260318.719 ; validation-accuracy: 0.538581491\n",
      "Step 18600 : loss 813944.438 ; validation-accuracy: 0.538396537\n",
      "Step 18610 : loss 550098.938 ; validation-accuracy: 0.539315283\n",
      "Step 18620 : loss 277537.656 ; validation-accuracy: 0.54111135\n",
      "Step 18630 : loss 599906.875 ; validation-accuracy: 0.543300509\n",
      "Step 18640 : loss 487187.594 ; validation-accuracy: 0.544089556\n",
      "Step 18650 : loss 590245.562 ; validation-accuracy: 0.544602275\n",
      "Step 18660 : loss 368572.219 ; validation-accuracy: 0.544542074\n",
      "Step 18670 : loss 761888.438 ; validation-accuracy: 0.542340517\n",
      "Step 18680 : loss 605202.562 ; validation-accuracy: 0.541179299\n",
      "Step 18690 : loss 384519.219 ; validation-accuracy: 0.541852891\n",
      "Step 18700 : loss 904896.625 ; validation-accuracy: 0.542294681\n",
      "Step 18710 : loss 534455.438 ; validation-accuracy: 0.541370392\n",
      "Step 18720 : loss 199528 ; validation-accuracy: 0.541359425\n",
      "Step 18730 : loss 630216.438 ; validation-accuracy: 0.542767167\n",
      "Step 18740 : loss 404685.906 ; validation-accuracy: 0.543425322\n",
      "Step 18750 : loss 693605.812 ; validation-accuracy: 0.544286132\n",
      "Step 18760 : loss 438840.688 ; validation-accuracy: 0.545078397\n",
      "Step 18770 : loss 342997.344 ; validation-accuracy: 0.543102264\n",
      "Step 18780 : loss 504609.156 ; validation-accuracy: 0.540130138\n",
      "Step 18790 : loss 416687.812 ; validation-accuracy: 0.539060354\n",
      "Step 18800 : loss 867364 ; validation-accuracy: 0.53951633\n",
      "Step 18810 : loss 661541.562 ; validation-accuracy: 0.540986657\n",
      "Step 18820 : loss 272418.938 ; validation-accuracy: 0.542768657\n",
      "Step 18830 : loss 449608 ; validation-accuracy: 0.545351148\n",
      "Step 18840 : loss 378669.438 ; validation-accuracy: 0.546154261\n",
      "Step 18850 : loss 544468 ; validation-accuracy: 0.546492636\n",
      "Step 18860 : loss 513125.531 ; validation-accuracy: 0.546685398\n",
      "Step 18870 : loss 391596.656 ; validation-accuracy: 0.545183182\n",
      "Step 18880 : loss 671024.938 ; validation-accuracy: 0.54274708\n",
      "Step 18890 : loss 298046.594 ; validation-accuracy: 0.542581081\n",
      "Step 18900 : loss 786834.812 ; validation-accuracy: 0.542638183\n",
      "Step 18910 : loss 407493.188 ; validation-accuracy: 0.541268706\n",
      "Step 18920 : loss 226680.703 ; validation-accuracy: 0.541336358\n",
      "Step 18930 : loss 554296.938 ; validation-accuracy: 0.543375254\n",
      "Step 18940 : loss 267451.031 ; validation-accuracy: 0.543742\n",
      "Step 18950 : loss 568572.438 ; validation-accuracy: 0.544702232\n",
      "Step 18960 : loss 324316.062 ; validation-accuracy: 0.54528749\n",
      "Step 18970 : loss 631609.125 ; validation-accuracy: 0.544456422\n",
      "Step 18980 : loss 632461.875 ; validation-accuracy: 0.541686952\n",
      "Step 18990 : loss 298847.281 ; validation-accuracy: 0.541701913\n",
      "Step 19000 : loss 821884.125 ; validation-accuracy: 0.542422771\n",
      "Step 19010 : loss 587004.625 ; validation-accuracy: 0.542970657\n",
      "Step 19020 : loss 198876.328 ; validation-accuracy: 0.543993354\n",
      "Step 19030 : loss 726504.625 ; validation-accuracy: 0.545117497\n",
      "Step 19040 : loss 364055.5 ; validation-accuracy: 0.544703364\n",
      "Step 19050 : loss 604269.875 ; validation-accuracy: 0.544801474\n",
      "Step 19060 : loss 325212.562 ; validation-accuracy: 0.544393182\n",
      "Step 19070 : loss 369136.844 ; validation-accuracy: 0.54211992\n",
      "Step 19080 : loss 704628.562 ; validation-accuracy: 0.538955152\n",
      "Step 19090 : loss 283198.406 ; validation-accuracy: 0.539130628\n",
      "Step 19100 : loss 926848.625 ; validation-accuracy: 0.539792418\n",
      "Step 19110 : loss 835560.625 ; validation-accuracy: 0.538982332\n",
      "Step 19120 : loss 190902.031 ; validation-accuracy: 0.539888382\n",
      "Step 19130 : loss 761967.375 ; validation-accuracy: 0.542268217\n",
      "Step 19140 : loss 277376.844 ; validation-accuracy: 0.543819308\n",
      "Step 19150 : loss 653039.812 ; validation-accuracy: 0.545136809\n",
      "Step 19160 : loss 369303.812 ; validation-accuracy: 0.546121299\n",
      "Step 19170 : loss 472813.719 ; validation-accuracy: 0.544865608\n",
      "Step 19180 : loss 410307.281 ; validation-accuracy: 0.542895317\n",
      "Step 19190 : loss 423319.156 ; validation-accuracy: 0.542146146\n",
      "Step 19200 : loss 868349.938 ; validation-accuracy: 0.541960061\n",
      "Step 19210 : loss 671389.312 ; validation-accuracy: 0.541658163\n",
      "Step 19220 : loss 229034.891 ; validation-accuracy: 0.542484045\n",
      "Step 19230 : loss 593476.438 ; validation-accuracy: 0.544227839\n",
      "Step 19240 : loss 282460.5 ; validation-accuracy: 0.544745564\n",
      "Step 19250 : loss 655275.312 ; validation-accuracy: 0.545237\n",
      "Step 19260 : loss 347545.219 ; validation-accuracy: 0.545688093\n",
      "Step 19270 : loss 337926.344 ; validation-accuracy: 0.544179797\n",
      "Step 19280 : loss 509645.219 ; validation-accuracy: 0.541966617\n",
      "Step 19290 : loss 510382.094 ; validation-accuracy: 0.542130351\n",
      "Step 19300 : loss 759572 ; validation-accuracy: 0.542108536\n",
      "Step 19310 : loss 702232.125 ; validation-accuracy: 0.541735053\n",
      "Step 19320 : loss 254258 ; validation-accuracy: 0.542292595\n",
      "Step 19330 : loss 592073.812 ; validation-accuracy: 0.544162214\n",
      "Step 19340 : loss 279211.188 ; validation-accuracy: 0.544516206\n",
      "Step 19350 : loss 952907.125 ; validation-accuracy: 0.544821501\n",
      "Step 19360 : loss 421971.906 ; validation-accuracy: 0.544888377\n",
      "Step 19370 : loss 529579.125 ; validation-accuracy: 0.542767584\n",
      "Step 19380 : loss 671140.875 ; validation-accuracy: 0.540577412\n",
      "Step 19390 : loss 403561.344 ; validation-accuracy: 0.540173173\n",
      "Step 19400 : loss 850314.375 ; validation-accuracy: 0.540632546\n",
      "Step 19410 : loss 672891 ; validation-accuracy: 0.541215777\n",
      "Step 19420 : loss 206120.391 ; validation-accuracy: 0.541702032\n",
      "Step 19430 : loss 730276.812 ; validation-accuracy: 0.543976247\n",
      "Step 19440 : loss 272837.906 ; validation-accuracy: 0.543693781\n",
      "Step 19450 : loss 528126.875 ; validation-accuracy: 0.543560743\n",
      "Step 19460 : loss 643752.5 ; validation-accuracy: 0.54271239\n",
      "Step 19470 : loss 539802.062 ; validation-accuracy: 0.539656758\n",
      "Step 19480 : loss 785068.938 ; validation-accuracy: 0.536449194\n",
      "Step 19490 : loss 402728.438 ; validation-accuracy: 0.536894679\n",
      "Step 19500 : loss 856598.875 ; validation-accuracy: 0.537691057\n",
      "Step 19510 : loss 621958.625 ; validation-accuracy: 0.538773656\n",
      "Step 19520 : loss 234358.125 ; validation-accuracy: 0.540288687\n",
      "Step 19530 : loss 680009.625 ; validation-accuracy: 0.543250799\n",
      "Step 19540 : loss 312132.531 ; validation-accuracy: 0.543819249\n",
      "Step 19550 : loss 682924.688 ; validation-accuracy: 0.544448376\n",
      "Step 19560 : loss 439325.594 ; validation-accuracy: 0.544189274\n",
      "Step 19570 : loss 538747.812 ; validation-accuracy: 0.541887641\n",
      "Step 19580 : loss 847574.812 ; validation-accuracy: 0.539605379\n",
      "Step 19590 : loss 324316.438 ; validation-accuracy: 0.540178537\n",
      "Step 19600 : loss 745260.312 ; validation-accuracy: 0.542035639\n",
      "Step 19610 : loss 597906.688 ; validation-accuracy: 0.541534603\n",
      "Step 19620 : loss 209992.625 ; validation-accuracy: 0.540990353\n",
      "Step 19630 : loss 667732.688 ; validation-accuracy: 0.542764962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 19640 : loss 200125.125 ; validation-accuracy: 0.542964101\n",
      "Step 19650 : loss 427133.406 ; validation-accuracy: 0.54323411\n",
      "Step 19660 : loss 251987.016 ; validation-accuracy: 0.543709874\n",
      "Step 19670 : loss 660711.625 ; validation-accuracy: 0.542615771\n",
      "Step 19680 : loss 557299.562 ; validation-accuracy: 0.539697409\n",
      "Step 19690 : loss 264938.812 ; validation-accuracy: 0.538792491\n",
      "Step 19700 : loss 814695.812 ; validation-accuracy: 0.538361847\n",
      "Step 19710 : loss 524109.844 ; validation-accuracy: 0.53884542\n",
      "Step 19720 : loss 133487.234 ; validation-accuracy: 0.540417671\n",
      "Step 19730 : loss 569913.938 ; validation-accuracy: 0.543262899\n",
      "Step 19740 : loss 352150.219 ; validation-accuracy: 0.543956041\n",
      "Step 19750 : loss 602212.375 ; validation-accuracy: 0.544675946\n",
      "Step 19760 : loss 543691.188 ; validation-accuracy: 0.544719696\n",
      "Step 19770 : loss 722976.438 ; validation-accuracy: 0.542070806\n",
      "Step 19780 : loss 819852.375 ; validation-accuracy: 0.539227605\n",
      "Step 19790 : loss 279180.469 ; validation-accuracy: 0.538852751\n",
      "Step 19800 : loss 781014.125 ; validation-accuracy: 0.540148795\n",
      "Step 19810 : loss 565662 ; validation-accuracy: 0.541241825\n",
      "Step 19820 : loss 281929.25 ; validation-accuracy: 0.542055666\n",
      "Step 19830 : loss 529441.312 ; validation-accuracy: 0.544253767\n",
      "Step 19840 : loss 262167.469 ; validation-accuracy: 0.54441458\n",
      "Step 19850 : loss 408658.594 ; validation-accuracy: 0.54485178\n",
      "Step 19860 : loss 315697.938 ; validation-accuracy: 0.545268655\n",
      "Step 19870 : loss 483100.188 ; validation-accuracy: 0.543266296\n",
      "Step 19880 : loss 670102.312 ; validation-accuracy: 0.540064\n",
      "Step 19890 : loss 393554.062 ; validation-accuracy: 0.539713323\n",
      "Step 19900 : loss 742713.312 ; validation-accuracy: 0.540448904\n",
      "Step 19910 : loss 390949.344 ; validation-accuracy: 0.541232347\n",
      "Step 19920 : loss 308956.656 ; validation-accuracy: 0.54204005\n",
      "Step 19930 : loss 601558 ; validation-accuracy: 0.543639719\n",
      "Step 19940 : loss 415925 ; validation-accuracy: 0.543997169\n",
      "Step 19950 : loss 607949.875 ; validation-accuracy: 0.544280171\n",
      "Step 19960 : loss 355002 ; validation-accuracy: 0.542769313\n",
      "Step 19970 : loss 535393.875 ; validation-accuracy: 0.540602565\n",
      "Step 19980 : loss 628271.625 ; validation-accuracy: 0.536719799\n",
      "Step 19990 : loss 155253.125 ; validation-accuracy: 0.536957622\n",
      "Step 20000 : loss 850464.562 ; validation-accuracy: 0.53852582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int32, numpy=20000>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=850464.56>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.5385258>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "norm, norm_v = cnn.prep_train(ele_valid) \n",
    "mytrain = cnn.train_func()\n",
    "mytrain(cnn, optimizer, 200, ele_valid, norm, norm_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fe1c01a8090>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ytest_p, ytest = cnn.predict_x(ele_test)\n",
    "plt.scatter(ytest, ytest_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.34737352, 0.34761643, 0.3456105 , 0.34507918], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn._cor_tf(ytest_p, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.27565733, 0.26802287, 0.26034147, 0.253008  ], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn._cor_tf(ytest_pred_ls, ytest_ls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
